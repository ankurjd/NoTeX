{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pickle as pkl\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Input, Dropout, LSTM, Activation, Bidirectional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "metadata": {},
   "outputs": [],
   "source": [
    "datapath=\"C:/Users/aiden/Downloads/ProjectData/FeatureData/\"\n",
    "with open(datapath+\"X_Y\", \"rb\") as f:\n",
    "    X, Y = pkl.load(f)\n",
    "with open(\"C:/Users/aiden/Downloads/ProjectData/Vocab.pkl\", \"rb\") as f:\n",
    "    vocab = pkl.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(datapath+\"Train\", \"rb\") as f:\n",
    "    X_train, X_test = pkl.load(f)\n",
    "with open(datapath+\"Test\", \"rb\") as f:\n",
    "    X_test, Y_test = pkl.load(f)\n",
    "with open(datapath+\"Eval\", \"rb\") as f:\n",
    "    X_eval, Y_eval = pkl.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size=len(vocab)\n",
    "RELATION_VOCAB_SIZE=27"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CELoss(y_pred, x):\n",
    "    on_stroke_indicator=x[:,:,6]\n",
    "    #assumes that y_pred is log probabilities\n",
    "    #log_prob_of_symbol = tf.math.reduce_logsumexp(y_pred[:,:,RELATION_VOCAB_SIZE:], axis=2)\n",
    "    prob_of_symbol = tf.math.reduce_sum(y_pred[:,:,RELATION_VOCAB_SIZE:], axis=2)\n",
    "    return(tf.math.reduce_sum(on_stroke_indicator*(-tf.math.log(prob_of_symbol))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[0.0037037  0.0037037  0.0037037  0.0037037  0.0037037  0.0037037\n",
      "   0.0037037  0.0037037  0.0037037  0.0037037  0.0037037  0.0037037\n",
      "   0.0037037  0.0037037  0.0037037  0.0037037  0.0037037  0.0037037\n",
      "   0.0037037  0.0037037  0.0037037  0.0037037  0.0037037  0.0037037\n",
      "   0.0037037  0.0037037  0.0037037  0.00873786 0.00873786 0.00873786\n",
      "   0.00873786 0.00873786 0.00873786 0.00873786 0.00873786 0.00873786\n",
      "   0.00873786 0.00873786 0.00873786 0.00873786 0.00873786 0.00873786\n",
      "   0.00873786 0.00873786 0.00873786 0.00873786 0.00873786 0.00873786\n",
      "   0.00873786 0.00873786 0.00873786 0.00873786 0.00873786 0.00873786\n",
      "   0.00873786 0.00873786 0.00873786 0.00873786 0.00873786 0.00873786\n",
      "   0.00873786 0.00873786 0.00873786 0.00873786 0.00873786 0.00873786\n",
      "   0.00873786 0.00873786 0.00873786 0.00873786 0.00873786 0.00873786\n",
      "   0.00873786 0.00873786 0.00873786 0.00873786 0.00873786 0.00873786\n",
      "   0.00873786 0.00873786 0.00873786 0.00873786 0.00873786 0.00873786\n",
      "   0.00873786 0.00873786 0.00873786 0.00873786 0.00873786 0.00873786\n",
      "   0.00873786 0.00873786 0.00873786 0.00873786 0.00873786 0.00873786\n",
      "   0.00873786 0.00873786 0.00873786 0.00873786 0.00873786 0.00873786\n",
      "   0.00873786 0.00873786 0.00873786 0.00873786 0.00873786 0.00873786\n",
      "   0.00873786 0.00873786 0.00873786 0.00873786 0.00873786 0.00873786\n",
      "   0.00873786 0.00873786 0.00873786 0.00873786 0.00873786 0.00873786\n",
      "   0.00873786 0.00873786 0.00873786 0.00873786 0.00873786 0.00873786\n",
      "   0.00873786 0.00873786 0.00873786 0.00873786]\n",
      "  [0.03333333 0.03333333 0.03333333 0.03333333 0.03333333 0.03333333\n",
      "   0.03333333 0.03333333 0.03333333 0.03333333 0.03333333 0.03333333\n",
      "   0.03333333 0.03333333 0.03333333 0.03333333 0.03333333 0.03333333\n",
      "   0.03333333 0.03333333 0.03333333 0.03333333 0.03333333 0.03333333\n",
      "   0.03333333 0.03333333 0.03333333 0.00097087 0.00097087 0.00097087\n",
      "   0.00097087 0.00097087 0.00097087 0.00097087 0.00097087 0.00097087\n",
      "   0.00097087 0.00097087 0.00097087 0.00097087 0.00097087 0.00097087\n",
      "   0.00097087 0.00097087 0.00097087 0.00097087 0.00097087 0.00097087\n",
      "   0.00097087 0.00097087 0.00097087 0.00097087 0.00097087 0.00097087\n",
      "   0.00097087 0.00097087 0.00097087 0.00097087 0.00097087 0.00097087\n",
      "   0.00097087 0.00097087 0.00097087 0.00097087 0.00097087 0.00097087\n",
      "   0.00097087 0.00097087 0.00097087 0.00097087 0.00097087 0.00097087\n",
      "   0.00097087 0.00097087 0.00097087 0.00097087 0.00097087 0.00097087\n",
      "   0.00097087 0.00097087 0.00097087 0.00097087 0.00097087 0.00097087\n",
      "   0.00097087 0.00097087 0.00097087 0.00097087 0.00097087 0.00097087\n",
      "   0.00097087 0.00097087 0.00097087 0.00097087 0.00097087 0.00097087\n",
      "   0.00097087 0.00097087 0.00097087 0.00097087 0.00097087 0.00097087\n",
      "   0.00097087 0.00097087 0.00097087 0.00097087 0.00097087 0.00097087\n",
      "   0.00097087 0.00097087 0.00097087 0.00097087 0.00097087 0.00097087\n",
      "   0.00097087 0.00097087 0.00097087 0.00097087 0.00097087 0.00097087\n",
      "   0.00097087 0.00097087 0.00097087 0.00097087 0.00097087 0.00097087\n",
      "   0.00097087 0.00097087 0.00097087 0.00097087]\n",
      "  [0.0037037  0.0037037  0.0037037  0.0037037  0.0037037  0.0037037\n",
      "   0.0037037  0.0037037  0.0037037  0.0037037  0.0037037  0.0037037\n",
      "   0.0037037  0.0037037  0.0037037  0.0037037  0.0037037  0.0037037\n",
      "   0.0037037  0.0037037  0.0037037  0.0037037  0.0037037  0.0037037\n",
      "   0.0037037  0.0037037  0.0037037  0.00873786 0.00873786 0.00873786\n",
      "   0.00873786 0.00873786 0.00873786 0.00873786 0.00873786 0.00873786\n",
      "   0.00873786 0.00873786 0.00873786 0.00873786 0.00873786 0.00873786\n",
      "   0.00873786 0.00873786 0.00873786 0.00873786 0.00873786 0.00873786\n",
      "   0.00873786 0.00873786 0.00873786 0.00873786 0.00873786 0.00873786\n",
      "   0.00873786 0.00873786 0.00873786 0.00873786 0.00873786 0.00873786\n",
      "   0.00873786 0.00873786 0.00873786 0.00873786 0.00873786 0.00873786\n",
      "   0.00873786 0.00873786 0.00873786 0.00873786 0.00873786 0.00873786\n",
      "   0.00873786 0.00873786 0.00873786 0.00873786 0.00873786 0.00873786\n",
      "   0.00873786 0.00873786 0.00873786 0.00873786 0.00873786 0.00873786\n",
      "   0.00873786 0.00873786 0.00873786 0.00873786 0.00873786 0.00873786\n",
      "   0.00873786 0.00873786 0.00873786 0.00873786 0.00873786 0.00873786\n",
      "   0.00873786 0.00873786 0.00873786 0.00873786 0.00873786 0.00873786\n",
      "   0.00873786 0.00873786 0.00873786 0.00873786 0.00873786 0.00873786\n",
      "   0.00873786 0.00873786 0.00873786 0.00873786 0.00873786 0.00873786\n",
      "   0.00873786 0.00873786 0.00873786 0.00873786 0.00873786 0.00873786\n",
      "   0.00873786 0.00873786 0.00873786 0.00873786 0.00873786 0.00873786\n",
      "   0.00873786 0.00873786 0.00873786 0.00873786]\n",
      "  [0.03333333 0.03333333 0.03333333 0.03333333 0.03333333 0.03333333\n",
      "   0.03333333 0.03333333 0.03333333 0.03333333 0.03333333 0.03333333\n",
      "   0.03333333 0.03333333 0.03333333 0.03333333 0.03333333 0.03333333\n",
      "   0.03333333 0.03333333 0.03333333 0.03333333 0.03333333 0.03333333\n",
      "   0.03333333 0.03333333 0.03333333 0.00097087 0.00097087 0.00097087\n",
      "   0.00097087 0.00097087 0.00097087 0.00097087 0.00097087 0.00097087\n",
      "   0.00097087 0.00097087 0.00097087 0.00097087 0.00097087 0.00097087\n",
      "   0.00097087 0.00097087 0.00097087 0.00097087 0.00097087 0.00097087\n",
      "   0.00097087 0.00097087 0.00097087 0.00097087 0.00097087 0.00097087\n",
      "   0.00097087 0.00097087 0.00097087 0.00097087 0.00097087 0.00097087\n",
      "   0.00097087 0.00097087 0.00097087 0.00097087 0.00097087 0.00097087\n",
      "   0.00097087 0.00097087 0.00097087 0.00097087 0.00097087 0.00097087\n",
      "   0.00097087 0.00097087 0.00097087 0.00097087 0.00097087 0.00097087\n",
      "   0.00097087 0.00097087 0.00097087 0.00097087 0.00097087 0.00097087\n",
      "   0.00097087 0.00097087 0.00097087 0.00097087 0.00097087 0.00097087\n",
      "   0.00097087 0.00097087 0.00097087 0.00097087 0.00097087 0.00097087\n",
      "   0.00097087 0.00097087 0.00097087 0.00097087 0.00097087 0.00097087\n",
      "   0.00097087 0.00097087 0.00097087 0.00097087 0.00097087 0.00097087\n",
      "   0.00097087 0.00097087 0.00097087 0.00097087 0.00097087 0.00097087\n",
      "   0.00097087 0.00097087 0.00097087 0.00097087 0.00097087 0.00097087\n",
      "   0.00097087 0.00097087 0.00097087 0.00097087 0.00097087 0.00097087\n",
      "   0.00097087 0.00097087 0.00097087 0.00097087]\n",
      "  [0.0037037  0.0037037  0.0037037  0.0037037  0.0037037  0.0037037\n",
      "   0.0037037  0.0037037  0.0037037  0.0037037  0.0037037  0.0037037\n",
      "   0.0037037  0.0037037  0.0037037  0.0037037  0.0037037  0.0037037\n",
      "   0.0037037  0.0037037  0.0037037  0.0037037  0.0037037  0.0037037\n",
      "   0.0037037  0.0037037  0.0037037  0.00873786 0.00873786 0.00873786\n",
      "   0.00873786 0.00873786 0.00873786 0.00873786 0.00873786 0.00873786\n",
      "   0.00873786 0.00873786 0.00873786 0.00873786 0.00873786 0.00873786\n",
      "   0.00873786 0.00873786 0.00873786 0.00873786 0.00873786 0.00873786\n",
      "   0.00873786 0.00873786 0.00873786 0.00873786 0.00873786 0.00873786\n",
      "   0.00873786 0.00873786 0.00873786 0.00873786 0.00873786 0.00873786\n",
      "   0.00873786 0.00873786 0.00873786 0.00873786 0.00873786 0.00873786\n",
      "   0.00873786 0.00873786 0.00873786 0.00873786 0.00873786 0.00873786\n",
      "   0.00873786 0.00873786 0.00873786 0.00873786 0.00873786 0.00873786\n",
      "   0.00873786 0.00873786 0.00873786 0.00873786 0.00873786 0.00873786\n",
      "   0.00873786 0.00873786 0.00873786 0.00873786 0.00873786 0.00873786\n",
      "   0.00873786 0.00873786 0.00873786 0.00873786 0.00873786 0.00873786\n",
      "   0.00873786 0.00873786 0.00873786 0.00873786 0.00873786 0.00873786\n",
      "   0.00873786 0.00873786 0.00873786 0.00873786 0.00873786 0.00873786\n",
      "   0.00873786 0.00873786 0.00873786 0.00873786 0.00873786 0.00873786\n",
      "   0.00873786 0.00873786 0.00873786 0.00873786 0.00873786 0.00873786\n",
      "   0.00873786 0.00873786 0.00873786 0.00873786 0.00873786 0.00873786\n",
      "   0.00873786 0.00873786 0.00873786 0.00873786]]]\n"
     ]
    }
   ],
   "source": [
    "y_offstroke_vector=np.zeros(vocab_size)\n",
    "y_offstroke_vector[RELATION_VOCAB_SIZE:]=0.1/(vocab_size-RELATION_VOCAB_SIZE)\n",
    "y_offstroke_vector[:RELATION_VOCAB_SIZE]=0.9/RELATION_VOCAB_SIZE\n",
    "y_onstroke_vector=np.zeros(vocab_size)\n",
    "y_onstroke_vector[RELATION_VOCAB_SIZE:]=0.9/(vocab_size-RELATION_VOCAB_SIZE)\n",
    "y_onstroke_vector[:RELATION_VOCAB_SIZE]=0.1/RELATION_VOCAB_SIZE\n",
    "\n",
    "def get_y_pred(x, y_offstroke_vector, y_onstroke_vector):\n",
    "    #x input shape = (batch_size, sequence_len, 7)\n",
    "    y = np.zeros((x.shape[0], x.shape[1], y_offstroke_vector.shape[0]))\n",
    "    y=np.multiply.outer(x[:,:,6], y_onstroke_vector)+np.multiply.outer(1-x[:,:,6], y_offstroke_vector)\n",
    "    \n",
    "    #y[x[:,:,6] == 1] =  y_onstroke_vector\n",
    "    #print(x[:,:,6]==1)\n",
    "    #y[x[:,:,6] == 0] = y_offstroke_vector\n",
    "    return y\n",
    "#CELoss Test\n",
    "x=np.zeros((1, 5, 7))\n",
    "x[:,:,6]=[1,0,1,0,1]\n",
    "y_pred=get_y_pred(x, y_offstroke_vector, y_onstroke_vector)\n",
    "print(get_y_pred(x, y_offstroke_vector, y_onstroke_vector))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 122)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y_pred' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[319], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m CELoss(y_pred, x)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'y_pred' is not defined"
     ]
    }
   ],
   "source": [
    "CELoss(y_pred, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MathModel(input_shape, output_dim, regularize=False):\n",
    "    input = Input(shape=input_shape)\n",
    "    X = Bidirectional(LSTM(128, return_sequences = True, kernel_regularizer=tf.keras.regularizers.L1L2(l1=1e-5, l2=1e-4) if regularize else None))(input)\n",
    "    X = Dropout(0.5)(X)\n",
    "    X = Bidirectional(LSTM(128, return_sequences = True, kernel_regularizer=tf.keras.regularizers.L1L2(l1=1e-5, l2=1e-4) if regularize else None))(X)\n",
    "    X = Dropout(0.5)(X)\n",
    "    X = Bidirectional(LSTM(128, return_sequences = True, kernel_regularizer=tf.keras.regularizers.L1L2(l1=1e-5, l2=1e-4) if regularize else None))(X)\n",
    "    X = Dropout(0.5)(X)\n",
    "    X = Dense(output_dim+1, kernel_regularizer=tf.keras.regularizers.L1L2(l1=1e-5, l2=1e-4) if regularize else None)(X)\n",
    "    output = Activation('softmax')(X)\n",
    "    \n",
    "    model = Model(inputs=input,outputs=output)\n",
    "    model.add_loss(CELoss(output,input))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CTCLoss(y_true, y_pred):\n",
    "    # Compute the training-time loss value\n",
    "    batch_len = tf.cast(tf.shape(y_true)[0], dtype=\"int64\")\n",
    "    input_length = tf.cast(tf.shape(y_pred)[1], dtype=\"int64\")\n",
    "    label_length = tf.cast(tf.shape(y_true)[1], dtype=\"int64\")\n",
    "\n",
    "    input_length = input_length * tf.ones(shape=(batch_len, 1), dtype=\"int64\")\n",
    "    label_length = label_length * tf.ones(shape=(batch_len, 1), dtype=\"int64\")\n",
    "\n",
    "    loss = tf.keras.backend.ctc_batch_cost(y_true, y_pred, input_length, label_length)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_batch_predictions(pred):\n",
    "    input_len = np.ones(pred.shape[0]) * pred.shape[1]\n",
    "    # Use greedy search. For complex tasks, you can use beam search\n",
    "    results = tf.keras.backend.ctc_decode(pred, input_length=input_len, greedy=True)[0][0]\n",
    "    # Iterate over the results and get back the text\n",
    "    output_text = []\n",
    "    for result in results:\n",
    "        result = tf.strings.reduce_join(index_to_value[result]).numpy().decode(\"utf-8\")\n",
    "        output_text.append(result)\n",
    "    return output_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "class MathDataset(tf.keras.utils.Sequence):\n",
    "    def __init__(self, x, y, batch_size, X_train_data_len, Y_train_data_len):\n",
    "        self.x=x\n",
    "        self.y=y\n",
    "        self.batch_size=batch_size\n",
    "        self.X_train_data_len=X_train_data_len\n",
    "        self.Y_train_data_len=Y_train_data_len\n",
    "    def __len__(self):\n",
    "        return math.floor(len(self.x) / self.batch_size)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        max_x=max(self.X_train_data_len[idx * self.batch_size:(idx + 1) *\n",
    "        self.batch_size])\n",
    "        max_y=max(self.Y_train_data_len[idx * self.batch_size:(idx + 1) *\n",
    "        self.batch_size])\n",
    "        batch_x = self.x[idx * self.batch_size:(idx + 1) *\n",
    "        self.batch_size, :max_x]\n",
    "        batch_y = self.y[idx * self.batch_size:(idx + 1) *\n",
    "        self.batch_size, :max_y]\n",
    "\n",
    "        return (batch_x,batch_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 59)"
      ]
     },
     "execution_count": 416,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(trainData.__getitem__(0)[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainModel(model, trainData, evalData, learning_rate, momentum, epochs):\n",
    "    #model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate,clipvalue=0.5, clipnorm=0.5), loss=CTCLoss)\n",
    "    model.compile(optimizer=tf.keras.optimizers.SGD(learning_rate=learning_rate, momentum=momentum), loss=CTCLoss)\n",
    "    model.fit(x=trainData, validation_data=evalData, epochs=epochs)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "int"
      ]
     },
     "execution_count": 359,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(Y_train[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle as pkl\n",
    "with open(datapath+\"Train\", \"rb\") as f:\n",
    "    X_train, Y_train = pkl.load(f)\n",
    "with open(datapath+\"Test\", \"rb\") as f:\n",
    "    X_test, Y_test = pkl.load(f)\n",
    "with open(datapath+\"Eval\", \"rb\") as f:\n",
    "    X_eval, Y_eval = pkl.load(f)\n",
    "NUM_FEATURES=7\n",
    "len_train=len(X_train)\n",
    "len_test=len(X_test)\n",
    "len_eval=len(X_eval)\n",
    "max_X_train_len = max([len(sample) for sample in X_train])\n",
    "max_Y_train_len = max([len(sample) for sample in Y_train])\n",
    "max_X_test_len = max([len(sample) for sample in X_test])\n",
    "max_Y_test_len = max([len(sample) for sample in Y_test])\n",
    "max_X_eval_len = max([len(sample) for sample in X_eval])\n",
    "max_Y_eval_len = max([len(sample) for sample in Y_eval])\n",
    "padding_vector=np.array([0,0,0,0,0,0,1])\n",
    "eos_index=146\n",
    "blank_index=147\n",
    "\n",
    "X_train_data_len=[len(data) for data in X_train]\n",
    "Y_train_data_len=[len(data) for data in Y_train]\n",
    "X_test_data_len=[len(data) for data in X_test]\n",
    "Y_test_data_len=[len(data) for data in Y_test]\n",
    "X_eval_data_len=[len(data) for data in X_eval]\n",
    "Y_eval_data_len=[len(data) for data in Y_eval]\n",
    "padded_X_train=np.zeros((len_train, max_X_train_len, NUM_FEATURES), dtype=np.int32)+padding_vector\n",
    "padded_Y_train=np.zeros((len_train, max_Y_train_len), dtype = np.int32)+eos_index\n",
    "padded_X_test=np.zeros((len_test, max_X_test_len, NUM_FEATURES))+padding_vector\n",
    "padded_Y_test=np.zeros((len_test, max_Y_test_len), dtype=np.int32)+eos_index\n",
    "padded_X_eval=np.zeros((len_test, max_X_eval_len, NUM_FEATURES), dtype=np.int32)+padding_vector\n",
    "padded_Y_eval=np.zeros((len_test, max_Y_eval_len), dtype=np.int32)+eos_index\n",
    "for i in range(len_train):\n",
    "    sample_X = np.array(X_train[i])\n",
    "    padded_X_train[i,:len(sample_X),:]=sample_X\n",
    "    sample_Y = np.array(Y_train[i])\n",
    "    padded_Y_train[i,:len(sample_Y)]=sample_Y\n",
    "        \n",
    "for i in range(len_test):\n",
    "    sample_X = np.array(X_test[i])\n",
    "    padded_X_test[i,:len(sample_X),:]=sample_X\n",
    "    sample_Y = np.array(Y_test[i])\n",
    "    padded_Y_test[i,:len(sample_Y)]=sample_Y\n",
    "\n",
    "for i in range(len_eval):\n",
    "    sample_X = np.array(X_eval[i])\n",
    "    padded_X_eval[i,:len(sample_X),:]=sample_X\n",
    "    sample_Y = np.array(Y_eval[i])\n",
    "    padded_Y_eval[i,:len(sample_Y)]=sample_Y\n",
    "#trainData = MathDataset(padded_X_train[incorrectTrain], padded_Y_train[incorrectTrain], 32, list(np.array(X_train_data_len)[incorrectTrain]), list(np.array(Y_train_data_len)[incorrectTrain]))\n",
    "trainData = MathDataset(padded_X_train, padded_Y_train, 32, X_train_data_len, Y_train_data_len)\n",
    "testData = MathDataset(padded_X_test, padded_Y_test, 32, X_test_data_len, Y_test_data_len)\n",
    "evalData = MathDataset(padded_X_eval, padded_Y_eval, 32, X_eval_data_len, Y_eval_data_len)\n",
    "#evalData = MathDataset(padded_X_eval[incorrectEval], padded_Y_eval[incorrectEval], 32, list(np.array(X_eval_data_len)[incorrectEval]), list(np.array(Y_eval_data_len)[incorrectEval]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MathModel(input_shape=(None,7), output_dim=vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(855, 249, 7)"
      ]
     },
     "execution_count": 299,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padded_X_eval[correctEval].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "855"
      ]
     },
     "execution_count": 300,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(np.array(X_eval_data_len)[correctEval])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'CT' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[172], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m model\u001b[39m.\u001b[39mcompile(optimizer\u001b[39m=\u001b[39mtf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39moptimizers\u001b[39m.\u001b[39mSGD(learning_rate\u001b[39m=\u001b[39m\u001b[39m0.05\u001b[39m, momentum\u001b[39m=\u001b[39m\u001b[39m0.1\u001b[39m), lossCLoss\u001b[39m=\u001b[39mCT)\n\u001b[0;32m      2\u001b[0m inp \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray([[[\u001b[39m20.0\u001b[39m, \u001b[39m75.0\u001b[39m, \u001b[39m0.0\u001b[39m, \u001b[39m0.0\u001b[39m, \u001b[39m0.0\u001b[39m, \u001b[39m0.0\u001b[39m, \u001b[39m0\u001b[39m], [\u001b[39m30\u001b[39m, \u001b[39m40\u001b[39m, \u001b[39m5.0\u001b[39m, \u001b[39m6.0\u001b[39m, \u001b[39m1.0\u001b[39m, \u001b[39m-\u001b[39m\u001b[39m3.0\u001b[39m, \u001b[39m1\u001b[39m], [\u001b[39m30\u001b[39m, \u001b[39m40\u001b[39m, \u001b[39m2.0\u001b[39m, \u001b[39m4.0\u001b[39m, \u001b[39m-\u001b[39m\u001b[39m1.0\u001b[39m, \u001b[39m2.0\u001b[39m, \u001b[39m1\u001b[39m], [\u001b[39m30.0\u001b[39m, \u001b[39m30.0\u001b[39m, \u001b[39m0.0\u001b[39m, \u001b[39m0.0\u001b[39m, \u001b[39m0.0\u001b[39m, \u001b[39m0.0\u001b[39m, \u001b[39m0\u001b[39m], [\u001b[39m25\u001b[39m, \u001b[39m-\u001b[39m\u001b[39m35.0\u001b[39m, \u001b[39m1.0\u001b[39m, \u001b[39m2.0\u001b[39m, \u001b[39m1.0\u001b[39m, \u001b[39m-\u001b[39m\u001b[39m1.0\u001b[39m, \u001b[39m1\u001b[39m], [\u001b[39m20.0\u001b[39m, \u001b[39m-\u001b[39m\u001b[39m50.0\u001b[39m, \u001b[39m0.0\u001b[39m, \u001b[39m0.0\u001b[39m, \u001b[39m0.0\u001b[39m, \u001b[39m0.0\u001b[39m, \u001b[39m0\u001b[39m]]], dtype\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39mfloat32)\n\u001b[0;32m      3\u001b[0m out \u001b[39m=\u001b[39m model(inp)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'CT' is not defined"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer=tf.keras.optimizers.SGD(learning_rate=0.001, momentum=0.1), lossCLoss=CT)\n",
    "inp = np.array([[[20.0, 75.0, 0.0, 0.0, 0.0, 0.0, 0], [30, 40, 5.0, 6.0, 1.0, -3.0, 1], [30, 40, 2.0, 4.0, -1.0, 2.0, 1], [30.0, 30.0, 0.0, 0.0, 0.0, 0.0, 0], [25, -35.0, 1.0, 2.0, 1.0, -1.0, 1], [20.0, -50.0, 0.0, 0.0, 0.0, 0.0, 0]]], dtype=np.float32)\n",
    "out = model(inp)\n",
    "print(model.loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "correctTrain=[]\n",
    "incorrectTrain=[]\n",
    "for i, (lx, ly) in enumerate(zip(X_train_data_len, Y_train_data_len)):\n",
    "    if lx > 2*ly:\n",
    "        correctTrain.append(i)\n",
    "    else:\n",
    "        incorrectTrain.append(i)\n",
    "correctEval=[]\n",
    "incorrectEval=[]\n",
    "for i, (lx, ly) in enumerate(zip(X_eval_data_len, Y_eval_data_len)):\n",
    "    if lx > 2*ly:\n",
    "        correctEval.append(i)\n",
    "    else:\n",
    "        incorrectEval.append(i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2841"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(incorrect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_data_len=[len(data) for data in X_train]\n",
    "Y_train_data_len=[len(data) for data in Y_train]\n",
    "X_test_data_len=[len(data) for data in X_test]\n",
    "Y_test_data_len=[len(data) for data in Y_test]\n",
    "X_eval_data_len=[len(data) for data in X_eval]\n",
    "Y_eval_data_len=[len(data) for data in Y_eval]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NOTE ADD NONSEG TO VOCAB POTENTIALLY FOR OFFSTROKES WITHIN A SYMBOL \n",
    "#Make the CE Loss weighted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(855, 249, 7)"
      ]
     },
     "execution_count": 282,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padded_X_eval[correctEval].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0.,  63.,   0., 115.,   0.,  64.,   0., 146., 146., 146., 146.,\n",
       "       146., 146., 146., 146., 146., 146., 146., 146., 146., 146., 146.,\n",
       "       146., 146., 146., 146., 146., 146., 146., 146., 146., 146., 146.,\n",
       "       146., 146., 146., 146., 146., 146., 146., 146., 146., 146., 146.,\n",
       "       146., 146., 146., 146., 146., 146., 146., 146., 146., 146., 146.,\n",
       "       146., 146., 146., 146., 146., 146., 146., 146., 146., 146., 146.,\n",
       "       146., 146., 146., 146., 146., 146., 146., 146., 146., 146., 146.,\n",
       "       146., 146., 146., 146., 146., 146., 146., 146., 146., 146., 146.,\n",
       "       146., 146., 146., 146., 146., 146., 146., 146., 146., 146., 146.,\n",
       "       146., 146., 146., 146., 146., 146., 146., 146., 146., 146., 146.,\n",
       "       146., 146., 146., 146., 146., 146., 146., 146., 146., 146., 146.,\n",
       "       146., 146., 146., 146., 146., 146., 146., 146., 146., 146., 146.,\n",
       "       146., 146., 146., 146., 146., 146., 146., 146., 146., 146., 146.,\n",
       "       146., 146., 146., 146., 146., 146., 146., 146., 146., 146., 146.,\n",
       "       146., 146., 146., 146., 146., 146., 146., 146., 146., 146., 146.,\n",
       "       146., 146., 146., 146., 146., 146., 146., 146., 146., 146., 146.,\n",
       "       146., 146., 146., 146., 146., 146., 146., 146., 146., 146., 146.,\n",
       "       146., 146., 146., 146.])"
      ]
     },
     "execution_count": 347,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainData.y[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "308/308 [==============================] - 1504s 5s/step - loss: 120.0202 - val_loss: 117.7017\n",
      "Epoch 2/60\n",
      "308/308 [==============================] - 1476s 5s/step - loss: 119.1277 - val_loss: 122.1248\n",
      "Epoch 3/60\n",
      "308/308 [==============================] - 1489s 5s/step - loss: 119.0541 - val_loss: 116.5453\n",
      "Epoch 4/60\n",
      "308/308 [==============================] - 1460s 5s/step - loss: 118.1297 - val_loss: 116.0984\n",
      "Epoch 5/60\n",
      "214/308 [===================>..........] - ETA: 7:04 - loss: 116.8564"
     ]
    }
   ],
   "source": [
    "#new_model=trainModel(model, trainData, evalData, 0.001, 0.9, 50)\n",
    "full_model=trainModel(full_model, trainData, evalData, 0.0001, 0.9, 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n",
      "249 97\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[312], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(padded_X_eval[correctEval])):\n\u001b[1;32m----> 2\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mlen\u001b[39m(padded_X_eval[correctEval][i]), \u001b[39mlen\u001b[39m(padded_Y_eval[correctEval][i]))\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for i in range(len(padded_X_eval[correctEval])):\n",
    "    print(len(padded_X_eval[correctEval][i]), len(padded_Y_eval[correctEval][i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"C:/Users/aiden/Downloads/ProjectData/index_to_symbol.pkl\", \"rb\") as f:\n",
    "    index_to_symbol = pkl.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_batch_predictions(pred):\n",
    "    input_len = np.ones(pred.shape[0]) * pred.shape[1]\n",
    "    # Use greedy search. For complex tasks, you can use beam search\n",
    "    results = tf.keras.backend.ctc_decode(pred, input_length=input_len, greedy=True)[0][0]\n",
    "    batch_outputs=[]\n",
    "    for result in results:\n",
    "        output=[]\n",
    "        for sym in result:\n",
    "            sym=int(sym)\n",
    "            if sym != -1 and sym != vocab_size-1:\n",
    "                output.append(index_to_symbol[sym])\n",
    "        batch_outputs.append(output)\n",
    "    return batch_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 4s 4s/step\n",
      "[['Right', '0', 'Right', '\\\\lt', 'Right', 'x', 'Right', '\\\\lt', 'Right', '1'], ['Right', 'A', 'Right', '(', 'Right', 'B', 'Right', '+', 'Right', 'c', 'Right', ')', 'Right', '=', 'Right', 'A', 'Right', 'B', 'Right', '+', 'Right', 'A', 'Right', ')', 'Right'], ['Right', 'A', 'Right', '\\\\times', 'Right', '1', 'Right'], ['Right', 'A', 'Sub', '2', 'UFS', '\\\\gt', 'Right', 'B', 'Sub', '2', 'UFS'], ['Right', '\\\\forall', 'Right', 'x', 'Right', '\\\\in', 'Right', 'A', 'Right', 'COMMA', 'Right', '\\\\forall', 'Right', 'y', 'Right', '\\\\in', 'Right', 'B', 'Right', 'COMMA', 'Right', 'x', 'Right', 'Right'], ['Right', '\\\\forall', 'Right', 'a', 'Right', 'COMMA', 'Right', '\\\\forall', 'Right', '6', 'Right', 'COMMA', 'Right', '\\\\forall', 'Sub', '4', 'COMMA', 'Right', '(', 'Right', 'a', 'Sub', 'COMMA', 'UFS', '8', 'Right', 'COMMA', 'Right', 'c', 'Right', ')', 'Right', '=', 'Right', '(', 'Right', '(', 'Right', 'a', 'Right', 'COMMA', 'Right', '0', 'Right', ')', 'Right', 'COMMA', 'Right', 'c', 'Right', ')'], ['Right', '\\\\exists', 'Right', 'Y', 'Right', 'COMMA', 'Right', '\\\\gt', 'Right', '\\\\gt', 'Right'], ['Right', '(', 'Right', 'A', 'Sub', '2', 'UFS', 'B', 'Sub', '1', 'UFS', ')'], ['Right', '\\\\cos', 'Right', '(', 'Right', 'A', 'Right', '+', 'Right', 'B', 'Right', ')', 'Right'], ['Right', '\\\\exists', 'Right', '-', 'Right', 'i', 'Right', 'COMMA', 'Right', 'c', 'Sub', '1', 'UFS', '\\\\pi', 'Right', 'i', 'Right', ']', 'Right', '\\\\lt', 'Right', 'c', 'Sub', '2', 'UFS', '[', 'Right', 'Right', 'i', 'Right'], ['Right', '\\\\gamma', 'Right', '\\\\lt', 'Right', 'x', 'Right'], ['Right', '\\\\gamma', 'Right', '\\\\gt', 'Right', '\\\\gamma', 'Sub', '0', 'UFS', '\\\\gt', 'Right', '1'], ['Right', '\\\\exists', 'Right', '\\\\alpha', 'Right', 'COMMA', 'Right', '\\\\forall', 'Right', 'x', 'Right', '\\\\in', 'Right', 'i', 'Right', 'a', 'Right', 'COMMA', 'Right', '2', 'Right'], ['Right', '0', 'Right', '\\\\lt', 'Right', '\\\\gamma', 'Sub', 'i', 'UFS', '\\\\lt', 'Right', '1'], ['Right', 'A', 'Sub', '1', 'UFS', 'COMMA', 'UFS', 'A', 'Sub', '2', 'UFS', 'COMMA', 'Right', '\\\\ldots', 'Right', 'A', 'Sub', 'n', 'UFS'], ['UTF', 'd', 'NTB', '-', 'BTD', 'd', 'Right', 't', 'UFD', '(', 'Right', 'A', 'Right', 'COMMA', 'Right', 'B', 'Right', ')', 'Right', '=', 'Right', '(', 'UTF', 'd', 'Right', 'A', 'NTB', '-', 'BTD', 'd', 'Right', 't', 'Right', ')', 'Right', 'b', 'Right', ')', 'Right', '+', 'Right', '(', 'Right', 'A', 'Right', 'COMMA', 'UTF', 'd', 'Right', '\\\\beta', 'NTB', '-', 'BTD', 'd', 'Right'], ['Right', '0', 'Right', '\\\\leq', 'Right', '2', 'Right', '\\\\lt', 'Right', '1'], ['Right', 'A', 'Right', '=', 'Right', 'A', 'Sub', '1', 'UFS', '+', 'Right', 'A', 'Sub', '2', 'UFS'], ['Right', '\\\\forall', 'Right', 'a', 'Right', '\\\\in', 'Right', 'A', 'Right', 'COMMA', 'Right', '\\\\forall', 'Right', 'b', 'Right', '+', 'Right', '\\\\beta', 'Right', 'COMMA', 'Right', 'a', 'Right', 'Right'], ['Right', 'y', 'Sub', '1', 'UFS', '(', 'Right', 'z', 'Right', ')', 'Right', '\\\\lt', 'Right', 'y', 'Right', '(', 'Right', 'z', 'Right', ')', 'Right', '\\\\lt', 'Right', 'y', 'Sub', '2', 'UFS', '(', 'Right', 'z', 'Right', ')', 'Right'], ['Right', '\\\\forall', 'Right', 't', 'Right', '\\\\in', 'Right', '[', 'Sub', '0', 'Right', 'COMMA', 'Right', '2', 'Right', '\\\\pi', 'Right', ']', 'Right', 'COMMA', 'Right', '1', 'Right', '(', 'Right', 't', 'Right', 'Right', ')', 'Right', 'Right', 'Right'], ['Right', 'A', 'Right', '\\\\times', 'Right', '(', 'Right', 'B', 'Right', '\\\\times', 'Right', 'c', 'Right', ')', 'Right', '=', 'Right', '(', 'Right', 'A', 'Right', '\\\\times', 'Right', 'B', 'Right', ')', 'Right', '\\\\times', 'Right', '1', 'Right'], ['Right', '\\\\lim', 'LB', 'x', 'Right', '\\\\rightarrow', 'Right', '\\\\rightarrow', 'Right', '\\\\infty', 'UFL', 'g', 'Right', '1', 'Right', '3', 'Right', '=', 'Right'], ['Right', '1', 'Right', '-', 'Right', 'e', 'Sup', '1', 'DFS'], ['Right', '(', 'Right', '\\\\alpha', 'Sub', '1', 'UFS', 'COMMA', 'Right', '\\\\ldots', 'Right', '\\\\alpha', 'Sub', 'n', 'UFS', ')'], ['Right', '1', 'Right', '8', 'Right', '7', 'Right', '-', 'Right', '4', 'Right', '2', 'Right', '\\\\neq', 'Right', '-', 'Right', '2', 'Right', '2', 'Right'], ['Right', 'b', 'Right', '-', 'Right', 'x'], ['Right', 'x', 'Right', '=', 'Right', '\\\\tan', 'Right', '(', 'Right', 'y', 'Right', ')'], ['Right', 'l', 'Right', '(', 'Right', 'a', 'Right', 'b', 'Sup', '-', 'Right', '1', 'DFS', ')', 'Right', '=', 'Right', '1', 'Right', '(', 'Right', 'c', 'Right', 'a', 'Sup', '-', 'Right', '1', 'DFS'], ['UTF', 'd', 'Right', 'c', 'UFS-NTB', '-', 'BTD', 'n', 'Right', '\\\\sqrt', 'Inside', 'x', 'Right', 'Right', 'n', 'Right', '+', 'Right', '4', 'OFI-UFD'], ['Right', 'y', 'Right', '=', 'Right', 'a', 'Right', 'x', 'Sup', '2', 'DFS', '+', 'Right', 'e', 'Right'], ['Right', 'a', 'Right', '=', 'Right', '\\\\int', 'Sup', '2', 'STS', 'c', 'UFS', '\\\\sin', 'Right', '(', 'Right', 'y', 'Right', ')', 'Right', 'a', 'Right', 'y', 'Right', '+', 'Right', '\\\\int', 'Sup', 'R', 'Sub', 'a', 'UFS', 'a', 'Right', 'x', 'Right', 'Right']]\n"
     ]
    }
   ],
   "source": [
    "pred = new_model.predict(trainData.__getitem__(0)[0])\n",
    "print(decode_batch_predictions(pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Right': 0,\n",
       " 'Sub': 1,\n",
       " 'Sup': 2,\n",
       " 'Inside': 3,\n",
       " 'UTF': 4,\n",
       " 'NTB': 5,\n",
       " 'BTD': 6,\n",
       " 'UFD': 7,\n",
       " 'DFS': 8,\n",
       " 'UFS': 9,\n",
       " 'OFI': 10,\n",
       " 'DFS-NTB': 11,\n",
       " 'LB': 12,\n",
       " 'UFL': 13,\n",
       " 'STS': 14,\n",
       " 'DTI': 15,\n",
       " 'ITL': 16,\n",
       " 'DFL': 17,\n",
       " 'UFS-NTB': 18,\n",
       " 'DFS-UFD': 19,\n",
       " 'UFS-UFD': 20,\n",
       " 'DFS-DFS': 21,\n",
       " 'OFI-NTB': 22,\n",
       " 'OFI-UFD': 23,\n",
       " 'DFS-OFI': 24,\n",
       " 'OFI-OFI': 25,\n",
       " 'UFD-DFS': 26,\n",
       " 'Sup-UTF': 27,\n",
       " 'UFS-UTF': 28,\n",
       " 'UFL-UTF': 29,\n",
       " 'Inside-UTF': 30,\n",
       " 'UFD-OFI': 31,\n",
       " 'DFS-OFI-UFD': 32,\n",
       " 'NTB-UTF': 33,\n",
       " 'UFS-UFS': 34,\n",
       " 'DFL-UTF': 35,\n",
       " 'UFD-UFD': 36,\n",
       " 'UFS-OFI': 37,\n",
       " 'UFS-DFS': 38,\n",
       " 'Radical': 39,\n",
       " 'RTI': 40,\n",
       " 'RTI-UTF': 41,\n",
       " 'Radical-UTF': 42,\n",
       " '!': 43,\n",
       " '(': 44,\n",
       " ')': 45,\n",
       " '+': 46,\n",
       " '-': 47,\n",
       " '.': 48,\n",
       " '/': 49,\n",
       " '0': 50,\n",
       " '1': 51,\n",
       " '2': 52,\n",
       " '3': 53,\n",
       " '4': 54,\n",
       " '5': 55,\n",
       " '6': 56,\n",
       " '7': 57,\n",
       " '8': 58,\n",
       " '9': 59,\n",
       " '<': 60,\n",
       " '=': 61,\n",
       " '>': 62,\n",
       " 'A': 63,\n",
       " 'B': 64,\n",
       " 'C': 65,\n",
       " 'COMMA': 66,\n",
       " 'E': 67,\n",
       " 'F': 68,\n",
       " 'G': 69,\n",
       " 'H': 70,\n",
       " 'I': 71,\n",
       " 'L': 72,\n",
       " 'M': 73,\n",
       " 'N': 74,\n",
       " 'P': 75,\n",
       " 'R': 76,\n",
       " 'S': 77,\n",
       " 'T': 78,\n",
       " 'V': 79,\n",
       " 'X': 80,\n",
       " 'Y': 81,\n",
       " '[': 82,\n",
       " '\\\\Delta': 83,\n",
       " '\\\\alpha': 84,\n",
       " '\\\\beta': 85,\n",
       " '\\\\cos': 86,\n",
       " '\\\\div': 87,\n",
       " '\\\\exists': 88,\n",
       " '\\\\forall': 89,\n",
       " '\\\\gamma': 90,\n",
       " '\\\\geq': 91,\n",
       " '\\\\gt': 92,\n",
       " '\\\\in': 93,\n",
       " '\\\\infty': 94,\n",
       " '\\\\int': 95,\n",
       " '\\\\lambda': 96,\n",
       " '\\\\ldots': 97,\n",
       " '\\\\leq': 98,\n",
       " '\\\\lim': 99,\n",
       " '\\\\log': 100,\n",
       " '\\\\lt': 101,\n",
       " '\\\\mu': 102,\n",
       " '\\\\neq': 103,\n",
       " '\\\\phi': 104,\n",
       " '\\\\pi': 105,\n",
       " '\\\\pm': 106,\n",
       " '\\\\prime': 107,\n",
       " '\\\\rightarrow': 108,\n",
       " '\\\\sigma': 109,\n",
       " '\\\\sin': 110,\n",
       " '\\\\sqrt': 111,\n",
       " '\\\\sum': 112,\n",
       " '\\\\tan': 113,\n",
       " '\\\\theta': 114,\n",
       " '\\\\times': 115,\n",
       " '\\\\{': 116,\n",
       " '\\\\}': 117,\n",
       " ']': 118,\n",
       " 'a': 119,\n",
       " 'b': 120,\n",
       " 'c': 121,\n",
       " 'd': 122,\n",
       " 'e': 123,\n",
       " 'f': 124,\n",
       " 'g': 125,\n",
       " 'h': 126,\n",
       " 'i': 127,\n",
       " 'j': 128,\n",
       " 'k': 129,\n",
       " 'l': 130,\n",
       " 'm': 131,\n",
       " 'n': 132,\n",
       " 'o': 133,\n",
       " 'p': 134,\n",
       " 'q': 135,\n",
       " 'r': 136,\n",
       " 's': 137,\n",
       " 't': 138,\n",
       " 'u': 139,\n",
       " 'v': 140,\n",
       " 'w': 141,\n",
       " 'x': 142,\n",
       " 'y': 143,\n",
       " 'z': 144,\n",
       " '|': 145,\n",
       " 'EOS': 146,\n",
       " 'BLANK': 147}"
      ]
     },
     "execution_count": 440,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_46\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_49 (InputLayer)          [(None, None, 7)]    0           []                               \n",
      "                                                                                                  \n",
      " bidirectional_140 (Bidirection  (None, None, 256)   139264      ['input_49[0][0]']               \n",
      " al)                                                                                              \n",
      "                                                                                                  \n",
      " dropout_138 (Dropout)          (None, None, 256)    0           ['bidirectional_140[0][0]']      \n",
      "                                                                                                  \n",
      " bidirectional_141 (Bidirection  (None, None, 256)   394240      ['dropout_138[0][0]']            \n",
      " al)                                                                                              \n",
      "                                                                                                  \n",
      " dropout_139 (Dropout)          (None, None, 256)    0           ['bidirectional_141[0][0]']      \n",
      "                                                                                                  \n",
      " bidirectional_142 (Bidirection  (None, None, 256)   394240      ['dropout_139[0][0]']            \n",
      " al)                                                                                              \n",
      "                                                                                                  \n",
      " dropout_140 (Dropout)          (None, None, 256)    0           ['bidirectional_142[0][0]']      \n",
      "                                                                                                  \n",
      " dense_46 (Dense)               (None, None, 149)    38293       ['dropout_140[0][0]']            \n",
      "                                                                                                  \n",
      " activation_46 (Activation)     (None, None, 149)    0           ['dense_46[0][0]']               \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_83 (S  (None, None, 122)   0           ['activation_46[0][0]']          \n",
      " licingOpLambda)                                                                                  \n",
      "                                                                                                  \n",
      " tf.math.reduce_sum_82 (TFOpLam  (None, None)        0           ['tf.__operators__.getitem_83[0][\n",
      " bda)                                                            0]']                             \n",
      "                                                                                                  \n",
      " tf.math.log_41 (TFOpLambda)    (None, None)         0           ['tf.math.reduce_sum_82[0][0]']  \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_82 (S  (None, None)        0           ['input_49[0][0]']               \n",
      " licingOpLambda)                                                                                  \n",
      "                                                                                                  \n",
      " tf.math.negative_41 (TFOpLambd  (None, None)        0           ['tf.math.log_41[0][0]']         \n",
      " a)                                                                                               \n",
      "                                                                                                  \n",
      " tf.math.multiply_41 (TFOpLambd  (None, None)        0           ['tf.__operators__.getitem_82[0][\n",
      " a)                                                              0]',                             \n",
      "                                                                  'tf.math.negative_41[0][0]']    \n",
      "                                                                                                  \n",
      " tf.math.reduce_sum_83 (TFOpLam  ()                  0           ['tf.math.multiply_41[0][0]']    \n",
      " bda)                                                                                             \n",
      "                                                                                                  \n",
      " add_loss_41 (AddLoss)          ()                   0           ['tf.math.reduce_sum_83[0][0]']  \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 966,037\n",
      "Trainable params: 966,037\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "new_model.summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6737d4ed9008f34a36365f9afa168c058c7bcfc27ae9ebfad5913b219a0345d6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
