{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "aO1H2KLXaaZs"
      },
      "outputs": [],
      "source": [
        "from bs4 import BeautifulSoup\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "eEFqm8abrABO"
      },
      "outputs": [],
      "source": [
        "def getSoup(file):\n",
        "  with open(file, \"r\") as infile:\n",
        "    xml_string = infile.read()\n",
        "  soup = BeautifulSoup(xml_string, \"xml\")\n",
        "  #trace_strings = soup.find_all(\"trace\")\n",
        "  return soup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "WRVVtA8QWsbo"
      },
      "outputs": [],
      "source": [
        "def arrayToPoints (arr) :\n",
        "  points = []\n",
        "  for i in arr:\n",
        "    points.append(point(i[0], i[1]))\n",
        "  return(points)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "1H4kBwUum37U"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from rdp import rdp\n",
        "import math\n",
        "EPSILON = 1e-12\n",
        "MACHINE_EPSILON = 1.12e-16\n",
        "\n",
        "\n",
        "class point:\n",
        "  def __init__(self, x, y):\n",
        "    self.x = x\n",
        "    self.y = y\n",
        "#note calculations may be off because of int vs float\n",
        "def isMachineZero (val) : \n",
        "  return (val >= -MACHINE_EPSILON and val <= MACHINE_EPSILON)\n",
        "def hypot (x, y) : \n",
        "  return math.sqrt(x * x + y * y)\n",
        "#def point (x, y) : return ( Point(x,y) )\n",
        "def pointLength (p) : \n",
        "  return hypot(p.x, p.y)\n",
        "def pointNegate (p) : \n",
        "  return point(-p.x, -p.y)\n",
        "def pointAdd (p1, p2) : \n",
        "  return point(p1.x + p2.x, p1.y + p2.y)\n",
        "def pointSubtract (p1, p2) : \n",
        "  return point(p1.x - p2.x, p1.y - p2.y)\n",
        "def pointMultiplyScalar (p, n) : \n",
        "  return point(p.x * n, p.y * n)\n",
        "def pointDot (p1, p2) : \n",
        "  return p1.x * p2.x + p1.y * p2.y\n",
        "def pointDistance (p1, p2) : \n",
        "  return hypot(p1.x - p2.x, p1.y - p2.y)\n",
        "def pointNormalize (p, length = 1) : \n",
        "  return pointMultiplyScalar(p, (length / pointLength(p)) if pointLength(p) else 0) #POSSIBLE FLAW\n",
        "class createSegment: \n",
        "  def __init__(self, p, i, o):\n",
        "    self.p=p\n",
        "    self.i=i\n",
        "    self.o=o #POSSIBLE FLAW (CHANGED)\n",
        "\n",
        "def chordLengthParameterize (points, first, last)  :\n",
        "    u = [0]\n",
        "    for i in range(first+1, last+1):\n",
        "    #for (let i = first + 1 i <= last i++) :\n",
        "        #u[i - first] = u[i - first - 1] + pointDistance(points[i], points[i - 1])\n",
        "        u.append(u[i - first - 1] + pointDistance(points[i], points[i - 1]))\n",
        "    \n",
        "    for i in range(1, last-first+1):\n",
        "    #for (let i = 1, m = last - first i <= m i++) :\n",
        "        u[i] /= u[last-first]\n",
        "    \n",
        "    return u\n",
        "\n",
        "# Use Newton-Raphson iteration to find better root.\n",
        "def findRoot (curve, point, u) :\n",
        "    curve1 = []\n",
        "    curve2 = []\n",
        "    # Generate control vertices for Q'\n",
        "    for i in range(3) : #FLAG\n",
        "        curve1.append(pointMultiplyScalar(pointSubtract(curve[i + 1], curve[i]), 3))\n",
        "    \n",
        "    # Generate control vertices for Q''\n",
        "    for i in range(2):\n",
        "    #for (let i = 0 i <= 1 i++) :\n",
        "        curve2.append(pointMultiplyScalar(pointSubtract(curve1[i + 1], curve1[i]), 2))\n",
        "    \n",
        "    # Compute Q(u), Q'(u) and Q''(u)\n",
        "    pt = evaluate(3, curve, u)\n",
        "    pt1 = evaluate(2, curve1, u)\n",
        "    pt2 = evaluate(1, curve2, u)\n",
        "    diff = pointSubtract(pt, point)\n",
        "    df = pointDot(pt1, pt1) + pointDot(diff, pt2)\n",
        "    # u = u - f(u) / f'(u)\n",
        "    #return isMachineZero(df) ? u : u - pointDot(diff, pt1) / df\n",
        "    return (u if isMachineZero(df) else (u-pointDot(diff,pt1)/df))\n",
        "\n",
        "# Evaluate a bezier curve at a particular parameter value\n",
        "def evaluate (degree, curve, t) :\n",
        "    # Copy array\n",
        "    tmp = curve[:]#.slice() FLAG\n",
        "    # Triangle computation\n",
        "    for i in range(1, degree+1):\n",
        "    #for (let i = 1 i <= degree i++) :\n",
        "        for j in range(degree):\n",
        "        #for (let j = 0 j <= degree - i j++) :\n",
        "            tmp[j] = pointAdd(pointMultiplyScalar(tmp[j], 1 - t), pointMultiplyScalar(tmp[j + 1], t))\n",
        "\n",
        "    return tmp[0]\n",
        "\n",
        "def addCurve (segments, curve)  :\n",
        "    prev = segments[len(segments) - 1]\n",
        "    prev.o = pointSubtract(curve[1], curve[0])\n",
        "    segments.append(createSegment(curve[3], pointSubtract(curve[2], curve[3]), None))\n",
        "\n",
        "# Use least-squares method to find Bezier control points for region.\n",
        "def generateBezier (points, first, last, uPrime, tan1, tan2)  :\n",
        "    epsilon = EPSILON\n",
        "    #abs = Math.abs\n",
        "    pt1 = points[first]\n",
        "    pt2 = points[last]\n",
        "    # Create the C and X matrices\n",
        "    C = [[0, 0],[0, 0]]\n",
        "    X = [0, 0]\n",
        "    for i in range(0, last-first+1):\n",
        "    #for (let i = 0, l = last - first + 1 i < l i++) :\n",
        "        u = uPrime[i] \n",
        "        t = 1 - u\n",
        "        b = 3 * u * t\n",
        "        b0 = t * t * t\n",
        "        b1 = b * t\n",
        "        b2 = b * u\n",
        "        b3 = u * u * u\n",
        "        a1 = pointNormalize(tan1, b1)\n",
        "        a2 = pointNormalize(tan2, b2)\n",
        "        tmp = pointSubtract(pointSubtract(points[first + i], pointMultiplyScalar(pt1, b0 + b1)), pointMultiplyScalar(pt2, b2 + b3))\n",
        "        C[0][0] += pointDot(a1, a1)\n",
        "        C[0][1] += pointDot(a1, a2)\n",
        "        # C[1][0] += a1.dot(a2)\n",
        "        C[1][0] = C[0][1]\n",
        "        C[1][1] += pointDot(a2, a2)\n",
        "        X[0] += pointDot(a1, tmp)\n",
        "        X[1] += pointDot(a2, tmp)\n",
        "    \n",
        "    # Compute the determinants of C and X\n",
        "    detC0C1 = C[0][0] * C[1][1] - C[1][0] * C[0][1]\n",
        "    alpha1=None\n",
        "    alpha2=None\n",
        "    if (abs(detC0C1) > epsilon) :\n",
        "        # Kramer's rule\n",
        "        detC0X = C[0][0] * X[1] - C[1][0] * X[0]\n",
        "        detXC1 = X[0] * C[1][1] - X[1] * C[0][1]\n",
        "        # Derive alpha values\n",
        "        alpha1 = detXC1 / detC0C1\n",
        "        alpha2 = detC0X / detC0C1\n",
        "    \n",
        "    else :\n",
        "        # Matrix is under-determined, try assuming alpha1 == alpha2\n",
        "        c0 = C[0][0] + C[0][1]\n",
        "        c1 = C[1][0] + C[1][1]\n",
        "        #alpha1 = alpha2 = abs(c0) > epsilon ? X[0] / c0 : abs(c1) > epsilon ? X[1] / c1 : 0\n",
        "        alpha1 = alpha2 = X[0] / c0 if abs(c0) > epsilon else X[1] / c1 if abs(c1) > epsilon else 0\n",
        "    \n",
        "    # If alpha negative, use the Wu/Barsky heuristic (see text)\n",
        "    # (if alpha is 0, you get coincident control points that lead to\n",
        "    # divide by zero in any subsequent NewtonRaphsonRootFind() call.\n",
        "    segLength = pointDistance(pt2, pt1)\n",
        "    eps = epsilon * segLength\n",
        "    handle1 = None\n",
        "    handle2 = None\n",
        "    if (alpha1 < eps or alpha2 < eps) :\n",
        "        # fall back on standard (probably inaccurate) formula,\n",
        "        # and subdivide further if needed.\n",
        "        alpha1 = alpha2 = segLength / 3\n",
        "    \n",
        "    else :\n",
        "        # Check if the found control points are in the right order when\n",
        "        # projected onto the line through pt1 and pt2.\n",
        "        line = pointSubtract(pt2, pt1)\n",
        "        # Control points 1 and 2 are positioned an alpha distance out\n",
        "        # on the tangent vectors, left and right, respectively\n",
        "        handle1 = pointNormalize(tan1, alpha1)\n",
        "        handle2 = pointNormalize(tan2, alpha2)\n",
        "        if (pointDot(handle1, line) - pointDot(handle2, line) > segLength * segLength) :\n",
        "            # Fall back to the Wu/Barsky heuristic above.\n",
        "            alpha1 = alpha2 = segLength / 3\n",
        "            handle1 = handle2 = None # Force recalculation\n",
        "        \n",
        "    \n",
        "    # First and last control points of the Bezier curve are\n",
        "    # positioned exactly at the first and last data points\n",
        "    return [pt1, pointAdd(pt1, handle1 or pointNormalize(tan1, alpha1)), pointAdd(pt2, handle2 or pointNormalize(tan2, alpha2)), pt2]\n",
        "\n",
        "# Given set of points and their parameterization, try to find\n",
        "# a better parameterization.\n",
        "def reparameterize (points, first, last, u, curve) :\n",
        "    #for (let i = first i <= last i++) :\n",
        "    for i in range(first, last+1):\n",
        "        u[i - first] = findRoot(curve, points[i], u[i - first])\n",
        "    \n",
        "    # Detect if the new parameterization has reordered the points.\n",
        "    # In that case, we would fit the points of the path in the wrong order.\n",
        "    #for (let i = 1, l = u.length i < l i++) :\n",
        "    for i in range (1, len(u)):\n",
        "        if (u[i] <= u[i - 1]):\n",
        "            return False\n",
        "    \n",
        "    return True\n",
        "\n",
        "\n",
        "class error:\n",
        "  def __init__(self, error, index):\n",
        "    self.error = error\n",
        "    self.index = index\n",
        "# Find the maximum squared distance of digitized points to fitted curve.\n",
        "def findMaxError (points, first, last, curve, u)  :\n",
        "    index = math.floor((last - first + 1) / 2)\n",
        "    maxDist = 0\n",
        "    #for (let i = first + 1 i < last i++) :\n",
        "    for i in range (first+1, last):\n",
        "        P = evaluate(3, curve, u[i - first])\n",
        "        v = pointSubtract(P, points[i])\n",
        "        dist = v.x * v.x + v.y * v.y # squared\n",
        "        if (dist >= maxDist) :\n",
        "            maxDist = dist\n",
        "            index = i\n",
        "        \n",
        "    return error(maxDist, index)\n",
        "    #return :\n",
        "    #   error: maxDist,\n",
        "    #    index: index,\n",
        "    \n",
        "\n",
        "\n",
        "\n",
        "def fit (points, closed, error) :\n",
        "    #points=filterRepeats(points)\n",
        "    #points=rdpFilter(points,0.3)\n",
        "    length = len(points)\n",
        "    if length == 0 and type(length) == int:\n",
        "        return []\n",
        "    segments = [createSegment(points[0], None, None)]\n",
        "    if length == 1:\n",
        "      return segments\n",
        "    fitCubic(points, segments, error, 0, length - 1, \n",
        "    pointSubtract(points[1], points[0]), \n",
        "    pointSubtract(points[length - 2], points[length - 1]))\n",
        "    if (closed) :\n",
        "        segments.pop(0)\n",
        "        segments.pop()\n",
        "    \n",
        "    return segments\n",
        "#note MAY HAVE TO FIND ALTERNATIVE TO === instead of using ==\n",
        "def fitCubic (points, segments, error, first, last, tan1, tan2):\n",
        "    #  Use heuristic if region only has two points in it\n",
        "    if (last - first == 1) :\n",
        "        pt1 = points[first]\n",
        "        pt2 = points[last]\n",
        "        dist = pointDistance(pt1, pt2) / 3\n",
        "        addCurve(segments, [pt1, pointAdd(pt1, pointNormalize(tan1, dist)), pointAdd(pt2, pointNormalize(tan2, dist)), pt2])\n",
        "        return\n",
        "    \n",
        "    # Parameterize points, and attempt to fit curve\n",
        "    uPrime = chordLengthParameterize(points, first, last)\n",
        "    maxError = max(error, error * error)\n",
        "    split=None\n",
        "    parametersInOrder = True\n",
        "    # Try not 4 but 5 iterations\n",
        "    #for (let i = 0 i <= 4 i++) :\n",
        "    for i in range(5):\n",
        "        curve = generateBezier(points, first, last, uPrime, tan1, tan2)\n",
        "        #  Find max deviation of points to fitted curve\n",
        "        Max = findMaxError(points, first, last, curve, uPrime)\n",
        "        if (Max.error < error and parametersInOrder) :\n",
        "            addCurve(segments, curve)\n",
        "            #for segment in segments:\n",
        "            #  print((str(segment.i.x) if segment.i else \"None\") + \" \" + (str(segment.i.y) if segment.i else \"None\") + \" \" + (str(segment.o.x) if segment.o else \"None\") + \" \" + (str(segment.o.y) if segment.o else \"None\") + \" \" + (str(segment.p.x) if segment.p else \"None\") + \" \" + (str(segment.p.y) if segment.p else \"None\"))\n",
        "            return\n",
        "        \n",
        "        split = Max.index\n",
        "        # If error not too large, try reparameterization and iteration\n",
        "        if (Max.error >= maxError):\n",
        "            break\n",
        "        parametersInOrder = reparameterize(points, first, last, uPrime, curve)\n",
        "        maxError = Max.error\n",
        "    \n",
        "    # Fitting failed -- split at max error point and fit recursively\n",
        "    tanCenter = pointSubtract(points[split - 1], points[split + 1])\n",
        "    fitCubic(points, segments, error, first, split, tan1, tanCenter)\n",
        "    fitCubic(points, segments, error, split, last, pointNegate(tanCenter), tan2)\n",
        "\n",
        "\n",
        "def filterRepeats(points):\n",
        "  filtered_points=[]\n",
        "  for i in range(len(points)-1):\n",
        "    if points[i].x != points[i+1].x or points[i].y != points[i+1].y:\n",
        "      filtered_points.append(points[i])\n",
        "  filtered_points.append(points[len(points)-1])\n",
        "  return filtered_points\n",
        "def rdpFilter(points, epsilon):\n",
        "  arr=[]\n",
        "  for i in range(len(points)):\n",
        "    arr.append([points[i].x,points[i].y])\n",
        "  return arrayToPoints(rdp(arr, epsilon=epsilon))\n",
        "\n",
        "\n",
        "# Assign parameter values to digitized points\n",
        "# using relative distances between points.\n",
        "\n",
        "def svgPath (segments, closed, precision) :\n",
        "    length = len(segments)\n",
        "    precisionMultiplier = 10 ** precision\n",
        "    def Round(n, precisionMultiplier):\n",
        "      return ((round(n * precisionMultiplier) / precisionMultiplier) if precision < 16 else n)\n",
        "    def formatPair (x, y):\n",
        "      return (str(Round(x, precisionMultiplier)) + ',' + str(Round(y, precisionMultiplier)))\n",
        "    first = True\n",
        "    prevX = None\n",
        "    prevY = None\n",
        "    outX = None\n",
        "    outY = None\n",
        "    parts = []\n",
        "    if length==1:\n",
        "      #return [[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0]],[[segments[0].p.x,segments[0].p.y]]]\n",
        "      return 'M' + str(segments[0].p.x) + \",\" + str(segments[0].p.y) #CHANGED\n",
        "    \n",
        "    if (not length):\n",
        "        return ''\n",
        "    for i in range(length):\n",
        "    #for (let i = 0 i < length i++)\n",
        "        #addSegment(segments[i])\n",
        "        #if not(prevX==segments[i].p.x and prevY==segments[i].p.y):\n",
        "        segmentData = []\n",
        "        segment=segments[i]\n",
        "        #repeat=False\n",
        "        curX = segment.p.x\n",
        "        curY = segment.p.y\n",
        "        if (first) :\n",
        "            parts.append('M' + formatPair(curX, curY))\n",
        "        else :\n",
        "            inX = curX + (segment.i.x if segment.i else 0)\n",
        "            inY = curY + (segment.i.y if segment.i else 0)\n",
        "            if (not (inX == curX and inY == curY and outX == prevX and outY == prevY)) :\n",
        "                  # c = relative curveto:\n",
        "                  #segmentData.extend([prevX, prevY, outX-prevX, outY-prevY, inX - prevX, inY - prevY, curX - prevX, curY - prevY])\n",
        "                segmentData.extend([prevX, prevY, outX, outY, inX, inY, curX, curY])\n",
        "                parts.append('c' +\n",
        "                      formatPair(outX - prevX, outY - prevY) +\n",
        "                      ' ' +\n",
        "                      formatPair(inX - prevX, inY - prevY) +\n",
        "                      ' ' +\n",
        "                      formatPair(curX - prevX, curY - prevY))\n",
        "\n",
        "        prevX = curX\n",
        "        prevY = curY\n",
        "        outX = curX + (segment.o.x if segment.o else 0)\n",
        "        outY = curY + (segment.o.y if segment.o else 0)\n",
        "        first = False\n",
        "\n",
        "    # Close path by drawing first segment again\n",
        "    #return [allSegmentData, endPoints]\n",
        "    return ''.join(parts)\n",
        "\n",
        "def getSegmentsPathData (segments, closed, precision)  :\n",
        "    length = len(segments)\n",
        "    precisionMultiplier = 10 ** precision\n",
        "    def Round(n, precisionMultiplier):\n",
        "      return ((round(n * precisionMultiplier) / precisionMultiplier) if precision < 16 else n)\n",
        "    def formatPair (x, y):\n",
        "      return (str(Round(x, precisionMultiplier)) + ',' + str(Round(y, precisionMultiplier)))\n",
        "    first = True\n",
        "    prevX = None\n",
        "    prevY = None\n",
        "    outX = None\n",
        "    outY = None\n",
        "    parts = []\n",
        "    if length==1:\n",
        "      return [[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0]],[[segments[0].p.x,segments[0].p.y]]]\n",
        "      #return 'M' + str(segments[0].p.x) + \",\" + str(segments[0].p.y) #CHANGED\n",
        "    \n",
        "    if (not length):\n",
        "        return []\n",
        "    allSegmentData=[]\n",
        "    endPoints = []\n",
        "    for i in range(length):\n",
        "    #for (let i = 0 i < length i++)\n",
        "        #addSegment(segments[i])\n",
        "        #if not(prevX==segments[i].p.x and prevY==segments[i].p.y):\n",
        "        segmentData = []\n",
        "        segment=segments[i]\n",
        "        #repeat=False\n",
        "        curX = segment.p.x\n",
        "        curY = segment.p.y\n",
        "        if (first) :\n",
        "            parts.append('M' + formatPair(curX, curY))\n",
        "        else :\n",
        "            inX = curX + (segment.i.x if segment.i else 0)\n",
        "            inY = curY + (segment.i.y if segment.i else 0)\n",
        "            if (not (inX == curX and inY == curY and outX == prevX and outY == prevY)) :\n",
        "                  # c = relative curveto:\n",
        "                  #segmentData.extend([prevX, prevY, outX-prevX, outY-prevY, inX - prevX, inY - prevY, curX - prevX, curY - prevY])\n",
        "                segmentData.extend([prevX, prevY, outX, outY, inX, inY, curX, curY])\n",
        "                parts.append('c' +\n",
        "                      formatPair(outX - prevX, outY - prevY) +\n",
        "                      ' ' +\n",
        "                      formatPair(inX - prevX, inY - prevY) +\n",
        "                      ' ' +\n",
        "                      formatPair(curX - prevX, curY - prevY))\n",
        "\n",
        "                features = [segmentData[6]-segmentData[0], \n",
        "                            segmentData[7]-segmentData[1], \n",
        "                            math.sqrt((segmentData[0]-segmentData[2])**2+(segmentData[1]-segmentData[3])**2), \n",
        "                            math.sqrt((segmentData[6]-segmentData[4])**2+(segmentData[7]-segmentData[5])**2), \n",
        "                            math.atan2(segmentData[3]-segmentData[1], segmentData[2]-segmentData[0])-math.atan2(segmentData[7]-segmentData[1], segmentData[6]-segmentData[0]),\n",
        "                            math.atan2(segmentData[5]-segmentData[7], segmentData[4]-segmentData[6])-math.atan2(segmentData[1]-segmentData[7], segmentData[0]-segmentData[6]), 1]\n",
        "                allSegmentData.append(features)\n",
        "                endPoints.append([segmentData[6],segmentData[7]])\n",
        "            #else:\n",
        "              #print(\"bruh what\")\n",
        "\n",
        "        prevX = curX\n",
        "        prevY = curY\n",
        "        outX = curX + (segment.o.x if segment.o else 0)\n",
        "        outY = curY + (segment.o.y if segment.o else 0)\n",
        "        first = False\n",
        "\n",
        "    # Close path by drawing first segment again\n",
        "    return [allSegmentData, endPoints]\n",
        "    #return ''.join(parts)\n",
        "\n",
        "class options:\n",
        "  def __init__(self, closed, tolerance, precision):\n",
        "    self.closed = closed\n",
        "    self.tolerance = tolerance\n",
        "    self.precision=precision\n",
        "\n",
        "def f1(p):\n",
        "  return point(p.x, p.y)\n",
        "\n",
        "def f2(p):\n",
        "  return point(p[0], p[1])\n",
        "\n",
        "#def simplify(points, options) :\n",
        "#  return fit(list(map((f1 if (type(points[0].x) == int or type(points[0].x) == float) else f2), points)), options.closed, options.tolerance if options.tolerance else 2.5)\n",
        "#def getFeatures (points, options):\n",
        "\n",
        "def getSvgPath (points, options) :\n",
        "    if (len(points) == 0 and type(len(points))==int) :\n",
        "        return ''\n",
        "    return svgPath(fit(list(map(f1 if (type(points[0].x) == int or type(points[0].x) == float) else f2, points)), options.closed, options.tolerance if options.tolerance else 2.5), options.closed, options.precision if options.precision else 5)\n",
        "\n",
        "def getFeatures (points, options)  :\n",
        "    if (len(points) == 0 and type(len(points))==int) :\n",
        "        return []\n",
        "    return getSegmentsPathData(fit(list(map(f1 if (type(points[0].x) == int or type(points[0].x) == float) else f2, points)), options.closed, options.tolerance if options.tolerance else 2.5), options.closed, options.precision if options.precision else 5)\n",
        "    #return getSegmentsPathData(fit(points.map(typeof points[0].x == 'number' ? (p) => point(p.x, p.y) : (p) => point(p[0], p[1])), options.closed, options.tolerance ?? 2.5), options.closed, options.precision ?? 5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "error_files=[]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "id": "GR2AhqjZBKzA",
        "outputId": "6f79916c-83bc-468c-eb02-20d782952ffe"
      },
      "outputs": [],
      "source": [
        "def _parse_one_trace(trace_string):\n",
        "  '''if len(trace_string.split(\"\\n\"))==3:\n",
        "    trace_split = trace_string.split(\"\\n\")[1].split(\",\")\n",
        "  else:\n",
        "    trace_split = trace_string.split(\">\")\n",
        "  try:\n",
        "    trace_split = trace_string.split(\"\\n\")[1].split(\",\")\n",
        "  except:\n",
        "    print(trace_string.split(\"\\n\"))'''\n",
        "  trace_split=trace_string.string\n",
        "  if trace_split[0]==\"\\n\":\n",
        "    trace_split=trace_split[1:]\n",
        "  if trace_split[-1]==\"\\n\":\n",
        "    trace_split=trace_split[:-1]\n",
        "  trace_split=trace_split.split(\",\")\n",
        "  a = [[float(s) for s in entry.strip().split(\" \")] for entry in trace_split]\n",
        "  return a\n",
        "\n",
        "\n",
        "def getSvg(file, tolerance=100):\n",
        "  with open(file, \"r\") as infile:\n",
        "    xml_string = infile.read()\n",
        "  soup = BeautifulSoup(xml_string, \"xml\")\n",
        "  trace_strings = soup.find_all(\"trace\")\n",
        "  a=\"\"\n",
        "  for trace_string in trace_strings:\n",
        "    path=getSvgPath(arrayToPoints(_parse_one_trace(trace_string)), options(False,tolerance,0))\n",
        "    #a += path[0]\n",
        "    a+=path\n",
        "  return a \n",
        "\n",
        "def parse_traces(file, tolerance=30):\n",
        "  with open(file, \"r\") as infile:\n",
        "    xml_string = infile.read()\n",
        "  soup = BeautifulSoup(xml_string, \"xml\")\n",
        "  trace_strings = soup.find_all(\"trace\")\n",
        "  a=[]\n",
        "  first = True\n",
        "  prev = None\n",
        "  for trace_string in trace_strings:\n",
        "    try:\n",
        "      path=getFeatures(arrayToPoints(_parse_one_trace(trace_string)), options(False,tolerance,0))\n",
        "    except:\n",
        "      print(\"error bezier curve: \")\n",
        "      print(file)\n",
        "    if not first:\n",
        "      try:\n",
        "        dx=path[1][len(path[1])-1][0] - prev[1][len(prev[1])-1][0]\n",
        "        dy=path[1][len(path[1])-1][1]-prev[1][len(prev[1])-1][1]\n",
        "      except:\n",
        "        print(\"path:\")\n",
        "        print(path)\n",
        "        print(\"trace_string:\")\n",
        "        print(trace_string.string)\n",
        "        print(\"file:\")\n",
        "        print(file)\n",
        "        error_files.append(file)\n",
        "      a += [[dx, dy, math.sqrt(dx**2/9+dy**2/9), math.sqrt(dx**2/9+dy**2/9), 0.0, 0.0, 0]]\n",
        "    a += path[0]\n",
        "    prev = path[:]\n",
        "    first=False\n",
        "  return a "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'M216.0,104.0c30.62545,-42.87563 16.17643,-14.35285 3.0,12.0c-2.97514,5.95029 -14.70437,4.0 -2.0,4.0c4.66667,0.0 9.33333,0.0 14.0,0.0c3.05447,0.0 11.33132,-1.0 11.0,-1.0M189.0,126.0c-11.32736,0.0 87.68895,1.0 78.0,1.0M215.0,146.0c-3.28632,-9.85896 -11.56794,48.56794 19.0,18.0M238.0,151.0c-4.94953,11.31321 -7.0,32.55464 -7.0,32.0M322.0,107.0c2.47215,-2.47215 -1.0,36.69195 -1.0,25.0M313.0,122.0c-7.77652,0.0 26.37685,-2.0 34.0,-2.0M408.0,53.0c0.0,-15.11859 0.1332,-3.97633 -17.0,38.0c-11.24843,27.55864 -7.80025,53.79899 -1.0,81.0c2.28278,9.13112 3.9088,15.1824 8.0,7.0M438.0,91.0c-8.90504,4.45252 0.86629,-0.09469 12.0,-16.0c1.93041,-2.75773 -8.06412,21.19236 -11.0,30.0c-1.42468,4.27404 -1.63067,7.0 -8.0,7.0c-9.66667,0.0 38.66667,0.0 29.0,0.0M407.0,123.0c-21.23067,0.0 88.90153,0.0 87.0,0.0M438.0,146.0c5.06979,-10.13958 -0.29457,5.29457 -2.0,7.0c-20.04864,20.04864 9.6451,17.3549 19.0,8.0M462.0,147.0c0.0,-8.6319 -21.36691,45.36691 -14.0,38.0M506.0,51.0c0.0,-0.66667 0.0,-1.33333 0.0,-2.0M506.0,51.0c0.0,-9.32604 1.0,33.17707 1.0,39.0c0.0,33.07532 -9.74806,65.49612 -24.0,94.0c-2.26,4.52001 -1.08099,1.08099 1.0,-1.0M534.0,38.0c-17.00302,0.0 13.65089,-19.95266 7.0,0.0c-3.15368,9.46104 -26.02369,20.0 -8.0,20.0c8.05707,0.0 11.89159,4.10841 19.0,-3.0M587.0,82.0c2.75801,-2.75801 -6.76582,40.76582 -2.0,36.0M573.0,105.0c-14.63482,0.0 25.95328,3.04672 32.0,-3.0M668.0,40.0c0.0,34.84834 -25.52624,64.31635 -20.0,103.0c0.85849,6.0094 8.2948,42.7052 18.0,33.0M693.0,85.0c0.0,9.94239 -0.44291,3.52595 16.0,-16.0c3.07638,-3.6532 -4.39378,11.96889 -6.0,20.0c-0.93214,4.66068 -0.02481,25.0 -6.0,25.0c-23.87029,0.0 30.79739,0.0 21.0,0.0M670.0,123.0c-50.63544,0.0 43.02147,-2.99761 61.0,-1.0c0.84532,0.09392 16.32129,2.0 10.0,2.0M693.0,136.0c12.41937,0.0 -16.03804,12.92391 -13.0,19.0c2.53165,5.06329 23.51958,4.0 29.0,4.0M714.0,143.0c0.0,-14.01983 -13.0,54.01983 -13.0,40.0M746.0,37.0c17.6616,0.0 -3.64758,128.29516 -11.0,143.0c-0.34869,0.69737 -2.0,5.01009 -2.0,2.0M768.0,22.0c-2.63523,-7.90569 16.27322,7.54644 20.0,15.0c3.3988,6.79761 -17.0,12.61645 -17.0,10.0M807.0,93.0c10.88032,-10.88032 -7.69117,42.30883 -9.0,41.0M791.0,125.0c0.0,-10.04988 40.04988,-3.0 30.0,-3.0M866.0,122.0c-1.52705,-1.52705 -1.42164,-1.21082 1.0,0.0M889.0,121.0c-0.33333,0.0 -0.66667,0.0 -1.0,0.0M908.0,120.0M957.0,113.0c-9.87317,0.0 36.50132,-5.25066 24.0,1.0M955.0,130.0c4.5096,4.5096 18.87354,1.0 27.0,1.0M1036.0,99.0c-3.85407,0.0 16.0,-14.09885 16.0,-22.0c0.0,-5.51765 -5.06262,9.83366 -7.0,15.0c-4.40398,11.74394 2.24477,20.25174 -9.0,24.0c-1.0,0.33333 -1.94591,1.0 -3.0,1.0c-10.1848,0.0 29.26722,2.0 27.0,2.0M1004.0,130.0c-3.53832,1.76916 20.64457,0.0 23.0,0.0c16.33333,0.0 32.66667,0.0 49.0,0.0c1.13542,0.0 27.85512,0.0 16.0,0.0M1033.0,157.0c-13.02312,13.02312 27.0,-10.84866 27.0,-2.0c0.0,7.55943 -13.82073,6.82073 -17.0,10.0c-0.61557,0.61557 10.09228,3.39485 11.0,4.0c20.1227,13.41514 -17.22707,30.77293 -27.0,21.0'"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "getSvg(\"C:/Users/aiden/Downloads/ProjectData/LGINKML/INKMLs/2014train/130_miguel.inkml\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "error_files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "hSpLriEUG64-"
      },
      "outputs": [],
      "source": [
        "#old y data generation\n",
        "\n",
        "from collections import defaultdict\n",
        "# todo: Add something to return the sequence of unique identifiers ('x_1' etc.)\n",
        "def parse_symbols_and_alignments(file):\n",
        "  with open(file, \"r\") as f:\n",
        "    string = f.read()\n",
        "  #lg=[]\n",
        "  rel=0 #BOOLEAN sorta\n",
        "  objects=[]\n",
        "  rels=defaultdict(lambda: \"NoRel\")\n",
        "  for part in string.split(\"\\n\"):\n",
        "    line=part.split(\", \")\n",
        "    if (line[0]==\"# Relations from SRT:\"):\n",
        "      rel=1\n",
        "    else:\n",
        "      if (line[0]!=''):\n",
        "        if rel:\n",
        "          #if rel > 1:\n",
        "          rels[(line[1], line[2])]=line[3]\n",
        "          #rel+=1\n",
        "          #prev=line[1]\n",
        "        else:\n",
        "          if (line[0][0]==\"#\"):\n",
        "            continue\n",
        "          del line[3]\n",
        "          objects.append((line[1:3], [int(l) for l in line[3:]]))\n",
        "  def key(obj):\n",
        "    return min(obj[1])\n",
        "  objects=sorted(objects, key=key)\n",
        "  output=[]\n",
        "\n",
        "  output.append(objects[0][0][1])\n",
        "  prev=objects[0][0][0]\n",
        "  #print(rels)\n",
        "  for ob in objects[1:]:\n",
        "    #print((ob[0][0], prev))\n",
        "    output.append(rels[(prev, ob[0][0])])\n",
        "    output.append(ob[0][1])\n",
        "    prev=ob[0][0]\n",
        "    #output.append(ob[0][1])\n",
        "    #output.append(rels[ob[0][0]])\n",
        "  '''try:\n",
        "    output.append(objects[-1][0][1])\n",
        "  except:\n",
        "    print(file)'''\n",
        "  #return(objects, rels)\n",
        "  return(output)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "class Node:\n",
        "  def __init__(self, symbol, relations, parent, strokes):\n",
        "    #self.id = id\n",
        "    self.symbol = symbol\n",
        "    self.relations = relations\n",
        "    self.parent = parent\n",
        "    self.strokes = strokes\n",
        "  '''def get_root(self, nodes):\n",
        "    node=self\n",
        "    while(nodes[node].parent!=None):\n",
        "      node=nodes[node].parent\n",
        "    #node=Node(self.symbol,self.relations,self.parent,self.strokes)\n",
        "    #while(nodes[node.parent].parent != None):\n",
        "    #  node=nodes[node.parent]\n",
        "    return node'''\n",
        "\n",
        "def get_root(node, nodes):\n",
        "    while(nodes[node].parent!=None):\n",
        "      node=nodes[node].parent\n",
        "    return node\n",
        "\n",
        "\n",
        "#nodes={\"A_1\" : Node(\"A_1\", \"A\", [\"Right\"], [\"x_1\"], None, ), }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "from collections import defaultdict\n",
        "def lg_to_tree(file):\n",
        "  with open(file, \"r\") as f:\n",
        "    string = f.read()\n",
        "  rel=0 #BOOLEAN sorta\n",
        "  nodes=defaultdict(lambda: Node(None, [], None, []))\n",
        "  for part in string.split(\"\\n\"):\n",
        "    line=part.split(\", \")\n",
        "    if (line[0]==\"# Relations from SRT:\"):\n",
        "      rel=1\n",
        "    else:\n",
        "      if (line[0]!=''):\n",
        "        if rel:\n",
        "          #if rel > 1:\n",
        "          nodes[line[1]].relations.append((line[2],line[3]))\n",
        "          nodes[line[2]].parent=line[1]\n",
        "          #rels[(line[1], line[2])]=line[3]\n",
        "          #rel+=1\n",
        "          #prev=line[1]\n",
        "        else:\n",
        "          if (line[0][0]==\"#\"):\n",
        "            continue\n",
        "          del line[3]\n",
        "          nodes[line[1]].symbol=line[2]\n",
        "          nodes[line[1]].strokes=line[3:]\n",
        "  return(nodes)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "length=0\n",
        "def traverse_tree(tree, current, order):\n",
        "  strokes=current.strokes\n",
        "  relations_order={\"Above\":1, \"Below\":2, \"Inside\":3, \"Sup\":4, \"Sub\":5, \"Right\":6}\n",
        "  relations=sorted(current.relations, key = lambda rel: relations_order[rel[1]])\n",
        "  ord=order\n",
        "  global length\n",
        "  for x in range(len(strokes)):\n",
        "    ord[strokes[x]]=length\n",
        "    length+=1\n",
        "  for i in range(len(relations)):\n",
        "    ord=traverse_tree(tree, tree[relations[i][0]], ord)\n",
        "  #if len(relations)==0:\n",
        "  return(ord)\n",
        "\n",
        "def reorder(file):\n",
        "  tree=lg_to_tree(file)\n",
        "  order = {}\n",
        "  root = get_root(list(tree.keys())[0], tree)\n",
        "  #for i in range(len(root.strokes)):\n",
        "    #order[root.strokes[i]]=i\n",
        "  global length\n",
        "  length=0\n",
        "  return(traverse_tree(tree, tree[root], order))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {},
      "outputs": [],
      "source": [
        "def convert_sequence(sequence):\n",
        "    symbols=sequence[::2]\n",
        "    relations=sequence[1::2]\n",
        "    return(symbols, relations)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['NTB']\n",
            "['BTD']\n",
            "['Sup']\n",
            "['DFS', 'UFD']\n",
            "['UTF']\n",
            "['NTB']\n",
            "['BTD']\n",
            "['Right']\n",
            "['Right']\n",
            "['Right']\n",
            "['Right']\n",
            "['Sup']\n",
            "['DFS', 'UFD']\n",
            "['UTF']\n",
            "['NTB']\n",
            "['BTD']\n",
            "['Right']\n",
            "['Right']\n",
            "['Right']\n",
            "['Right']\n",
            "['Sup']\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "'\\\\frac{1}{r^{2}}=\\\\frac{1}{(R-m)^{2}}+\\\\frac{1}{(R+m)^{2}}'"
            ]
          },
          "execution_count": 60,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#\\frac{9x^2 + 5}{2}\n",
        "\n",
        "#symbols = ['9','x','2','-','2','fractionbar','5','\\\\cdot ','x','2','fractionbar','5']\n",
        "#relations = [\"Right\", \"Sup\", \"DFS\", \"UTF\", \"NTB\", \"BTD\", \"UFD\", \"Right\", \"Sub\", \"OST\", \"BTD\"]\n",
        "\n",
        "symbols, relations=convert_sequence(['1', 'NTB', '-', 'BTD', 'r', 'Sup', '2', 'DFS-UFD', '=', 'UTF', '1', 'NTB', '-', 'BTD', '(', 'Right', 'R', 'Right', '-', 'Right', 'm', 'Right', ')', 'Sup', '2', 'DFS-UFD', '+', 'UTF', '1', 'NTB', '-', 'BTD', '(', 'Right', 'R', 'Right', '+', 'Right', 'm', 'Right', ')', 'Sup', '2'])\n",
        "\n",
        "def parse_latex(symbols, relations):\n",
        "  utf=0\n",
        "  open_brackets=0\n",
        "  latex_string=symbols[0]\n",
        "  for i in range(len(relations)):\n",
        "    s=symbols[i+1]\n",
        "    full_rel=relations[i]\n",
        "    split_rel=full_rel.split('-')\n",
        "    add_symbol=False\n",
        "    print(split_rel)\n",
        "    for rel in split_rel:\n",
        "      if rel in [\"DFS\", \"UFS\", \"OFI\", \"UFD\"]:\n",
        "        #latex_string+=(\"}\"+s)\n",
        "        latex_string+=\"}\"\n",
        "        open_brackets-=1\n",
        "        add_symbol=True\n",
        "      #if rel == \"BTD\":\n",
        "        #latex_string+=(s+\"}\")\n",
        "        #print(latex_string)\n",
        "      if rel == \"NTB\":\n",
        "        #print(latex_string)\n",
        "        if utf:\n",
        "          latex_string+=(\"}{\")\n",
        "          utf-=1\n",
        "        else:\n",
        "          latex_string=\"\\\\frac{\"+latex_string+\"}{\"\n",
        "          open_brackets+=1\n",
        "      if rel == \"UTF\":\n",
        "        latex_string+=(\"\\\\frac{\"+s)\n",
        "        open_brackets+=1\n",
        "        utf+=1\n",
        "      if rel == \"Sub\":\n",
        "        latex_string+=(\"_{\"+s)\n",
        "        open_brackets+=1\n",
        "      if rel == \"Sup\":\n",
        "        latex_string+=(\"^{\"+s)\n",
        "        open_brackets+=1\n",
        "      if rel in [\"Inside\", \"Right\", \"BTD\"]:\n",
        "        add_symbol=True\n",
        "      #  latex_string+=s\n",
        "    \n",
        "      '''if rel == \"OST\":\n",
        "        if utf:\n",
        "          latex_string+=(\"}}{\")\n",
        "          utf-=1\n",
        "        else:\n",
        "          latex_string=\"\\\\frac{\"+latex_string+\"}}{\"\n",
        "          '''\n",
        "      #if rel in [\"Inside\", \"Right\"]:\n",
        "        #latex_string+=s\n",
        "    if add_symbol:\n",
        "      latex_string+=s\n",
        "  latex_string+=(\"}\")*open_brackets\n",
        "  return latex_string\n",
        "  \n",
        "parse_latex(symbols, relations)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "missing_relations=set()\n",
        "missing_relations_freq=defaultdict(lambda: 0)\n",
        "pop_errors=[]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [],
      "source": [
        "arr=[]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pickle as pkl\n",
        "from collections import defaultdict\n",
        "with open(\"C:/Users/aiden/Downloads/ProjectData/Vocab.pkl\", \"rb\") as f:\n",
        "    vocab = pkl.load(f)\n",
        "last_symbol=None\n",
        "new_relations=[]\n",
        "new_rels=defaultdict(lambda: [])\n",
        "def traverse_relations(tree, current, new_rels, incoming_rel, prev_symbol):\n",
        "  relations_order={\"Above\":1, \"Below\":2, \"Inside\":3, \"Sup\":4, \"Sub\":5, \"Right\":6}\n",
        "  #print(current)\n",
        "  relations=sorted(tree[current].relations, key = lambda rel: relations_order[rel[1]])\n",
        "  last_symbol=current\n",
        "  if len(relations) > 0:\n",
        "    #tree[current].symbol == \"-\" and \n",
        "    if relations[0][1]==\"Above\":\n",
        "      if (prev_symbol):\n",
        "        new_rels[prev_symbol].pop()\n",
        "        new_rels[prev_symbol].append(\"UTF\")\n",
        "      #new_relations.append(\"UTF\")\n",
        "      #new_relations.append(relations[i][0])\n",
        "      #new_relations.append(\"BTD\")\n",
        "      #new_relations.append(relations[i][0])\n",
        "    #elif relations[0][1]==\"Below\":\n",
        "    #  new_rels[]\n",
        "    elif relations[0][1]==\"Below\":\n",
        "      new_rels[current].append(\"LB\")\n",
        "    else:\n",
        "      new_rels[current].append(relations[0][1])\n",
        "      #new_relations.append(relations[i][1])\n",
        "      #new_relations.append(relations[i][0])\n",
        "    for i in range(len(relations)):\n",
        "      thing=traverse_relations(tree, relations[i][0], new_rels, relations[i][1], last_symbol)#CHANGED\n",
        "      last_symbol=thing[0]\n",
        "      new_rels=thing[1]\n",
        "      if relations[i][1]==\"Above\":\n",
        "        new_rels[current].append(\"BTD\")\n",
        "  else:\n",
        "    new_rels[current]=[]\n",
        "  if incoming_rel==\"Above\":\n",
        "    new_rels[last_symbol].append(\"NTB\")\n",
        "  elif incoming_rel==\"Below\":\n",
        "    if tree[prev_symbol].symbol==\"\\lim\":\n",
        "      new_rels[last_symbol].append(\"UFL\")\n",
        "    else:\n",
        "      new_rels[last_symbol].append(\"UFD\")\n",
        "  elif incoming_rel==\"Sub\":\n",
        "    new_rels[last_symbol].append(\"UFS\")\n",
        "  elif incoming_rel==\"Sup\":\n",
        "    new_rels[last_symbol].append(\"DFS\")\n",
        "  elif incoming_rel==\"Inside\":\n",
        "    new_rels[last_symbol].append(\"OFI\")\n",
        "  #print(last_symbol)\n",
        "  return (last_symbol, new_rels)\n",
        "\n",
        "def convert_relations(file):\n",
        "  #arr=[]\n",
        "  tree=lg_to_tree(file)\n",
        "  root = get_root(list(tree.keys())[0], tree)\n",
        "  try:\n",
        "    new_rels=traverse_relations(tree, root, defaultdict(lambda: []), None, None)[1]\n",
        "    output=[]\n",
        "    not_in_vocab=False\n",
        "    for symbol in new_rels:\n",
        "      print(symbol)\n",
        "      print(new_rels[symbol])\n",
        "      #arr.append(tree[symbol].symbol)\n",
        "      output.append(vocab[tree[symbol].symbol])\n",
        "      if len(new_rels[symbol]):\n",
        "        relation=\"-\".join(new_rels[symbol])\n",
        "        if relation in vocab:\n",
        "          output.append(vocab[relation])\n",
        "          #arr.append(relation)\n",
        "        else:\n",
        "          print(\"missing: \" +relation)\n",
        "          missing_relations.add(relation)\n",
        "          missing_relations_freq[relation]+=1\n",
        "          not_in_vocab=True\n",
        "  except:\n",
        "    print(\"pop error: \"+file)\n",
        "    pop_errors.append(file)\n",
        "    return None\n",
        "  \n",
        "  \n",
        "  if not_in_vocab:\n",
        "    return None\n",
        "  #print(arr)\n",
        "  return output\n",
        "\n",
        "def get_latex(file):\n",
        "  arr=[]\n",
        "  tree=lg_to_tree(file)\n",
        "  root = get_root(list(tree.keys())[0], tree)\n",
        "  try:\n",
        "    new_rels=traverse_relations(tree, root, defaultdict(lambda: []), None, None)[1]\n",
        "    output=[]\n",
        "    not_in_vocab=False\n",
        "    for symbol in new_rels:\n",
        "      arr.append(tree[symbol].symbol)\n",
        "      output.append(vocab[tree[symbol].symbol])\n",
        "      if len(new_rels[symbol]):\n",
        "        relation=\"-\".join(new_rels[symbol])\n",
        "        if relation in vocab:\n",
        "          output.append(vocab[relation])\n",
        "          arr.append(relation)\n",
        "        else:\n",
        "          print(\"missing: \" +relation)\n",
        "          missing_relations.add(relation)\n",
        "          missing_relations_freq[relation]+=1\n",
        "          not_in_vocab=True\n",
        "  except:\n",
        "    print(\"pop error: \"+file)\n",
        "    pop_errors.append(file)\n",
        "    return None\n",
        "  \n",
        "  \n",
        "  if not_in_vocab:\n",
        "    return None\n",
        "  converted_sequence=convert_sequence(arr[:-1])\n",
        "  return parse_latex(converted_sequence[0], converted_sequence[1])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['NTB']\n",
            "['BTD']\n",
            "['Sup']\n",
            "['DFS', 'UFD']\n",
            "['UTF']\n",
            "['NTB']\n",
            "['BTD']\n",
            "['Right']\n",
            "['Right']\n",
            "['Right']\n",
            "['Right']\n",
            "['Sup']\n",
            "['DFS', 'UFD']\n",
            "['UTF']\n",
            "['NTB']\n",
            "['BTD']\n",
            "['Right']\n",
            "['Right']\n",
            "['Right']\n",
            "['Right']\n",
            "['Sup']\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "'\\\\frac{1}{r^{2}}=\\\\frac{1}{(R-m)^{2}}+\\\\frac{1}{(R+m)^{2}}'"
            ]
          },
          "execution_count": 66,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "get_latex(\"C:/Users/aiden/Downloads/ProjectData/LGINKML/LGs/2014train/80_jorge.lg\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
        "def add_to_vocab(symbol, vocab, index):\n",
        "    for key in vocab:\n",
        "        if vocab[key]>=index:\n",
        "            vocab[key]+=1\n",
        "    vocab[symbol]=index\n",
        "    vocab=dict(sorted(vocab.items(), key=lambda item: item[1]))\n",
        "    with open(\"C:/Users/aiden/Downloads/ProjectData/Vocab.pkl\", \"wb\") as f:\n",
        "        pkl.dump(vocab, f)\n",
        "def add_relation_to_vocab(relation, vocab, num_relations):\n",
        "    add_to_vocab(relation, vocab, num_relations)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'Right': 0,\n",
              " 'Sub': 1,\n",
              " 'Sup': 2,\n",
              " 'Inside': 3,\n",
              " 'UTF': 4,\n",
              " 'NTB': 5,\n",
              " 'BTD': 6,\n",
              " 'UFD': 7,\n",
              " 'DFS': 8,\n",
              " 'UFS': 9,\n",
              " 'OFI': 10,\n",
              " 'DFS-NTB': 11,\n",
              " 'UFL': 12,\n",
              " 'LB': 13,\n",
              " 'UFS-NTB': 14,\n",
              " 'DFS-UFD': 15,\n",
              " 'UFS-UFD': 16,\n",
              " 'DFS-DFS': 17,\n",
              " 'OFI-NTB': 18,\n",
              " 'OFI-UFD': 19,\n",
              " 'DFS-OFI': 20,\n",
              " 'UFD-DFS': 21,\n",
              " '!': 22,\n",
              " '(': 23,\n",
              " ')': 24,\n",
              " '+': 25,\n",
              " '-': 26,\n",
              " '.': 27,\n",
              " '/': 28,\n",
              " '0': 29,\n",
              " '1': 30,\n",
              " '2': 31,\n",
              " '3': 32,\n",
              " '4': 33,\n",
              " '5': 34,\n",
              " '6': 35,\n",
              " '7': 36,\n",
              " '8': 37,\n",
              " '9': 38,\n",
              " '<': 39,\n",
              " '=': 40,\n",
              " '>': 41,\n",
              " 'A': 42,\n",
              " 'B': 43,\n",
              " 'C': 44,\n",
              " 'COMMA': 45,\n",
              " 'E': 46,\n",
              " 'F': 47,\n",
              " 'G': 48,\n",
              " 'H': 49,\n",
              " 'I': 50,\n",
              " 'L': 51,\n",
              " 'M': 52,\n",
              " 'N': 53,\n",
              " 'P': 54,\n",
              " 'R': 55,\n",
              " 'S': 56,\n",
              " 'T': 57,\n",
              " 'V': 58,\n",
              " 'X': 59,\n",
              " 'Y': 60,\n",
              " '[': 61,\n",
              " '\\\\Delta': 62,\n",
              " '\\\\alpha': 63,\n",
              " '\\\\beta': 64,\n",
              " '\\\\cos': 65,\n",
              " '\\\\div': 66,\n",
              " '\\\\exists': 67,\n",
              " '\\\\forall': 68,\n",
              " '\\\\gamma': 69,\n",
              " '\\\\geq': 70,\n",
              " '\\\\gt': 71,\n",
              " '\\\\in': 72,\n",
              " '\\\\infty': 73,\n",
              " '\\\\int': 74,\n",
              " '\\\\lambda': 75,\n",
              " '\\\\ldots': 76,\n",
              " '\\\\leq': 77,\n",
              " '\\\\lim': 78,\n",
              " '\\\\log': 79,\n",
              " '\\\\lt': 80,\n",
              " '\\\\mu': 81,\n",
              " '\\\\neq': 82,\n",
              " '\\\\phi': 83,\n",
              " '\\\\pi': 84,\n",
              " '\\\\pm': 85,\n",
              " '\\\\prime': 86,\n",
              " '\\\\rightarrow': 87,\n",
              " '\\\\sigma': 88,\n",
              " '\\\\sin': 89,\n",
              " '\\\\sqrt': 90,\n",
              " '\\\\sum': 91,\n",
              " '\\\\tan': 92,\n",
              " '\\\\theta': 93,\n",
              " '\\\\times': 94,\n",
              " '\\\\{': 95,\n",
              " '\\\\}': 96,\n",
              " ']': 97,\n",
              " 'a': 98,\n",
              " 'b': 99,\n",
              " 'c': 100,\n",
              " 'd': 101,\n",
              " 'e': 102,\n",
              " 'f': 103,\n",
              " 'g': 104,\n",
              " 'h': 105,\n",
              " 'i': 106,\n",
              " 'j': 107,\n",
              " 'k': 108,\n",
              " 'l': 109,\n",
              " 'm': 110,\n",
              " 'n': 111,\n",
              " 'o': 112,\n",
              " 'p': 113,\n",
              " 'q': 114,\n",
              " 'r': 115,\n",
              " 's': 116,\n",
              " 't': 117,\n",
              " 'u': 118,\n",
              " 'v': 119,\n",
              " 'w': 120,\n",
              " 'x': 121,\n",
              " 'y': 122,\n",
              " 'z': 123,\n",
              " '|': 124}"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "$\\frac{1}{r^2} = \\frac{1}{(R - m)^2} + \\frac{1}{(R + m)^2}$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "FpyHKnXsJXov"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "error bezier curve: \n",
            "C:/Users/aiden/Downloads/ProjectData/LGINKML/INKMLs/2012/002-equation003.inkml\n"
          ]
        }
      ],
      "source": [
        "import pickle as pkl\n",
        "import os\n",
        "years=[\"2012\", \"2013\", \"2014train\", \"2014test\", \"2016\", \"2019\"]\n",
        "#years = [\"2019\"]\n",
        "#train=False\n",
        "#name=\"LG\"\n",
        "#datapath=\"C:/Users/aiden/Downloads/ProjectData/\"+year+\"/\"+ (\"Train/\" if train else \"Test/\") + name\n",
        "X=[]\n",
        "Y=[]\n",
        "count=0\n",
        "with open(\"C:/Users/aiden/Downloads/ProjectData/Vocab.pkl\", \"rb\") as f:\n",
        "    vocab = pkl.load(f)\n",
        "for year in years:\n",
        "    directory=\"C:/Users/aiden/Downloads/ProjectData/LGINKML/INKMLs/\"+year+\"/\"\n",
        "    for filename in os.listdir(directory):\n",
        "        #the filename unincluding .inkml\n",
        "        lgpath=\"C:/Users/aiden/Downloads/ProjectData/LGINKML/LGs/\"+year+\"/\"+filename[:len(filename)-6]+\".lg\"\n",
        "        if os.path.exists(lgpath):\n",
        "            X.append(parse_traces(directory+filename, tolerance=25))\n",
        "            LG=convert_relations(lgpath)\n",
        "            if LG:\n",
        "                Y.append(LG)\n",
        "            else:\n",
        "                print(\"no corresponding relation in vocab: \"+lgpath)\n",
        "\n",
        "        else:\n",
        "            print(\"missing file:\")\n",
        "            print(lgpath)\n",
        "        count += 1\n",
        "\n",
        "        if count % 100 == 0: print(count)\n",
        "datapath=\"C:/Users/aiden/Downloads/ProjectData/FeatureData/\"\n",
        "with open(datapath+\"X_Y\", \"wb\") as f:\n",
        "    pkl.dump((X,Y), f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<?xml version=\"1.0\" encoding=\"utf-8\"?>\n",
              "<ink xmlns=\"http://www.w3.org/2003/InkML\">\n",
              "<traceFormat>\n",
              "<channel name=\"X\" type=\"decimal\"/>\n",
              "<channel name=\"Y\" type=\"decimal\"/>\n",
              "</traceFormat>\n",
              "<annotation type=\"category\">Arithmetic</annotation>\n",
              "<annotation type=\"expression\">80</annotation>\n",
              "<annotation type=\"UI\">80_jorge</annotation>\n",
              "<annotation type=\"writer\">jorge</annotation>\n",
              "<annotation type=\"truth\">$\\frac{1}{r^2} = \\frac{1}{(R - m)^2} + \\frac{1}{(R + m)^2}$</annotation>\n",
              "<annotationXML encoding=\"Content-MathML\" type=\"truth\">\n",
              "<math xmlns=\"http://www.w3.org/1998/Math/MathML\">\n",
              "<mrow>\n",
              "<mfrac xml:id=\"_1\">\n",
              "<mn xml:id=\"1_1\">1</mn>\n",
              "<msup>\n",
              "<mi xml:id=\"r_1\">r</mi>\n",
              "<mn xml:id=\"2_1\">2</mn>\n",
              "</msup>\n",
              "</mfrac>\n",
              "<mrow>\n",
              "<mo xml:id=\"=_1\">=</mo>\n",
              "<mrow>\n",
              "<mfrac xml:id=\"_2\">\n",
              "<mn xml:id=\"1_2\">1</mn>\n",
              "<mrow>\n",
              "<mo xml:id=\"(_1\">(</mo>\n",
              "<mrow>\n",
              "<mi xml:id=\"R_1\">R</mi>\n",
              "<mrow>\n",
              "<mo xml:id=\"-_1\">-</mo>\n",
              "<mrow>\n",
              "<mi xml:id=\"m_1\">m</mi>\n",
              "<msup>\n",
              "<mo xml:id=\")_1\">)</mo>\n",
              "<mn xml:id=\"2_2\">2</mn>\n",
              "</msup>\n",
              "</mrow>\n",
              "</mrow>\n",
              "</mrow>\n",
              "</mrow>\n",
              "</mfrac>\n",
              "<mrow>\n",
              "<mo xml:id=\"+_1\">+</mo>\n",
              "<mfrac xml:id=\"_3\">\n",
              "<mn xml:id=\"1_3\">1</mn>\n",
              "<mrow>\n",
              "<mo xml:id=\"(_2\">(</mo>\n",
              "<mrow>\n",
              "<mi xml:id=\"R_2\">R</mi>\n",
              "<mrow>\n",
              "<mo xml:id=\"+_2\">+</mo>\n",
              "<mrow>\n",
              "<mi xml:id=\"m_2\">m</mi>\n",
              "<msup>\n",
              "<mo xml:id=\")_2\">)</mo>\n",
              "<mn xml:id=\"2_3\">2</mn>\n",
              "</msup>\n",
              "</mrow>\n",
              "</mrow>\n",
              "</mrow>\n",
              "</mrow>\n",
              "</mfrac>\n",
              "</mrow>\n",
              "</mrow>\n",
              "</mrow>\n",
              "</mrow>\n",
              "</math>\n",
              "</annotationXML>\n",
              "<trace id=\"0\">\n",
              "728 54, 729 64, 728 93, 726 117, 725 128, 725 133, 725 138, 725 139, 725 140, 726 141\n",
              "</trace>\n",
              "<trace id=\"1\">\n",
              "652 174, 645 175, 703 170, 720 169, 758 166, 768 165, 779 164, 810 162, 841 160, 851 159, 870 157, 878 157, 887 156, 901 155, 907 155, 917 155, 921 155, 925 155, 928 155, 933 155, 935 155, 936 155\n",
              "</trace>\n",
              "<trace id=\"2\">\n",
              "706 233, 709 236, 715 230, 715 228, 715 226, 715 225, 715 226, 716 229, 716 231, 717 234, 717 236, 718 239, 718 243, 719 248, 719 251, 720 254, 721 256, 721 258, 722 262, 723 264, 723 265, 724 266, 724 267, 725 268, 725 267, 725 266, 724 263, 724 260, 723 258, 723 255, 722 252\n",
              "</trace>\n",
              "<trace id=\"3\">\n",
              "717 241, 713 235, 712 233, 711 231, 710 230, 709 228, 709 227, 709 226, 709 225, 710 224, 711 223, 713 221, 716 220, 718 219, 721 218, 724 217, 728 216, 732 216, 736 215, 740 214, 744 214, 748 214, 751 213, 755 213, 757 213, 760 214, 761 214, 763 214, 764 214, 766 214, 767 215\n",
              "</trace>\n",
              "<trace id=\"4\">\n",
              "801 207, 802 204, 800 204, 798 205, 797 204, 797 203, 797 202, 797 201, 797 200, 798 198, 799 197, 800 196, 803 195, 805 195, 806 195, 807 196, 808 196, 809 198, 810 199, 810 204, 810 206, 809 208, 808 211, 807 213, 806 215, 804 217, 801 220, 800 221, 798 222, 798 223, 797 223, 798 223, 800 223, 801 223, 803 223, 805 224, 807 224, 809 225, 811 226, 815 228, 816 229, 818 230, 819 230, 820 231, 822 231, 825 231, 826 231, 828 231, 830 231, 832 231, 834 231, 836 230, 840 229, 842 228\n",
              "</trace>\n",
              "<trace id=\"5\">\n",
              "994 137, 994 142, 991 143, 984 145, 983 146, 985 146, 986 146, 989 146, 992 146, 995 146, 1004 145, 1009 145, 1014 145, 1018 145, 1026 145, 1029 145, 1031 145, 1034 146, 1034 147, 1033 147, 1029 149\n",
              "</trace>\n",
              "<trace id=\"6\">\n",
              "984 164, 991 166, 995 166, 1003 165, 1011 165, 1019 165, 1022 165, 1027 165, 1029 165, 1031 165, 1034 165, 1035 165\n",
              "</trace>\n",
              "<trace id=\"7\">\n",
              "1151 89, 1151 87, 1151 80, 1151 75, 1151 71, 1151 70, 1151 67, 1151 65, 1152 64, 1152 65, 1152 66, 1152 68, 1152 72, 1153 75, 1153 79, 1153 83, 1154 87, 1154 91, 1155 95, 1155 99, 1155 103, 1155 106, 1156 110, 1156 113, 1156 116, 1156 119, 1157 121, 1157 124, 1157 125, 1157 127, 1157 128, 1157 129, 1157 130, 1157 129, 1157 128, 1157 127, 1158 127\n",
              "</trace>\n",
              "<trace id=\"8\">\n",
              "1096 149, 1094 149, 1078 150, 1075 151, 1076 152, 1077 153, 1079 154, 1081 155, 1093 156, 1103 157, 1114 157, 1121 157, 1127 157, 1142 156, 1158 156, 1175 155, 1185 154, 1194 154, 1214 153, 1224 152, 1234 152, 1244 151, 1254 151, 1264 150, 1273 150, 1294 149, 1304 148, 1314 147, 1324 147, 1352 146, 1361 145, 1370 145, 1378 145, 1386 144, 1393 144, 1400 144, 1407 144, 1417 144, 1426 144, 1429 144, 1432 144, 1434 144, 1435 144, 1436 144, 1437 144, 1437 145, 1436 145, 1435 145\n",
              "</trace>\n",
              "<trace id=\"9\">\n",
              "1084 208, 1084 207, 1089 190, 1091 189, 1093 188, 1094 188, 1093 188, 1093 189, 1091 189, 1089 190, 1088 191, 1085 192, 1083 193, 1082 195, 1080 196, 1078 198, 1072 204, 1070 206, 1068 209, 1066 211, 1060 219, 1058 222, 1057 224, 1055 227, 1053 230, 1052 234, 1048 241, 1047 244, 1046 248, 1044 252, 1043 256, 1042 263, 1042 271, 1042 274, 1042 278, 1043 281, 1043 284, 1044 288, 1046 291, 1047 294, 1049 297, 1050 300, 1052 304, 1057 310, 1060 312, 1062 315, 1065 317, 1068 319, 1073 324, 1076 325, 1078 327, 1080 328, 1082 330, 1084 331, 1086 332, 1087 333, 1089 334, 1090 334, 1090 335, 1090 333\n",
              "</trace>\n",
              "<trace id=\"10\">\n",
              "1113 224, 1118 261, 1119 269, 1120 276, 1120 278, 1120 279, 1120 280, 1120 279, 1120 278, 1120 276\n",
              "</trace>\n",
              "<trace id=\"11\">\n",
              "1109 233, 1104 230, 1124 214, 1130 213, 1133 213, 1138 214, 1145 221, 1146 226, 1143 235, 1138 241, 1136 243, 1129 249, 1126 251, 1125 252, 1125 253, 1126 254, 1127 255, 1128 256, 1133 258, 1135 260, 1138 262, 1142 263, 1145 265, 1149 267, 1152 269, 1158 272, 1160 274, 1162 275, 1164 277, 1165 278, 1166 279, 1168 279, 1169 280, 1170 280, 1171 281, 1172 281, 1173 281, 1174 281, 1175 281, 1176 280\n",
              "</trace>\n",
              "<trace id=\"12\">\n",
              "1210 247, 1209 247, 1246 250, 1251 250, 1252 250, 1252 249, 1252 248, 1252 247\n",
              "</trace>\n",
              "<trace id=\"13\">\n",
              "1275 226, 1276 226, 1285 258, 1284 262, 1284 263, 1283 264, 1283 265, 1282 265, 1282 264, 1281 263, 1281 260, 1282 255, 1282 252, 1283 249, 1284 246, 1285 244, 1286 241, 1290 235, 1292 233, 1294 232, 1295 231, 1299 231, 1301 232, 1303 233, 1305 235, 1307 236, 1310 241, 1311 244, 1312 247, 1313 250, 1313 252, 1314 254, 1314 258, 1313 259, 1313 260, 1313 259, 1312 259, 1312 257, 1311 255, 1311 253, 1311 250, 1311 247, 1311 244, 1311 241, 1312 238, 1314 236, 1315 234, 1318 233, 1323 232, 1326 233, 1328 234, 1331 235, 1333 237, 1336 239, 1337 241, 1338 244, 1339 246, 1339 249, 1339 253, 1339 255, 1339 257, 1338 258, 1338 259, 1338 260, 1338 261, 1338 262, 1338 261, 1338 260, 1338 259, 1338 258\n",
              "</trace>\n",
              "<trace id=\"14\">\n",
              "1324 186, 1321 185, 1362 217, 1368 237, 1369 247, 1370 262, 1370 267, 1369 272, 1368 277, 1363 290, 1358 299, 1352 307, 1346 315, 1341 322, 1338 325, 1334 330, 1332 332, 1331 333, 1329 335\n",
              "</trace>\n",
              "<trace id=\"15\">\n",
              "1359 187, 1371 171, 1376 172, 1379 179, 1380 183, 1375 193, 1372 197, 1366 201, 1365 202, 1362 203, 1363 203, 1365 203, 1369 203, 1373 203, 1376 205, 1379 209, 1380 211, 1380 212, 1380 213, 1381 216, 1383 217, 1386 218, 1388 218, 1392 218, 1394 217, 1398 216, 1402 214, 1404 213, 1405 212\n",
              "</trace>\n",
              "<trace id=\"16\">\n",
              "1476 114, 1480 143, 1482 152, 1483 159, 1483 164, 1484 165, 1484 166, 1484 165\n",
              "</trace>\n",
              "<trace id=\"17\">\n",
              "1458 147, 1455 146, 1484 142, 1491 141, 1499 141, 1502 141, 1503 141, 1504 141, 1504 142, 1503 142, 1503 143\n",
              "</trace>\n",
              "<trace id=\"18\">\n",
              "1586 101, 1590 97, 1611 73, 1612 75, 1612 77, 1613 80, 1614 95, 1614 103, 1616 116, 1616 120, 1617 121, 1617 123, 1617 122, 1616 121, 1615 121, 1615 122, 1614 122\n",
              "</trace>\n",
              "<trace id=\"19\">\n",
              "1589 132, 1584 132, 1630 131, 1635 131, 1636 131, 1639 131, 1638 131\n",
              "</trace>\n",
              "<trace id=\"20\">\n",
              "1535 159, 1547 162, 1562 162, 1579 163, 1600 163, 1608 163, 1626 164, 1655 164, 1664 164, 1693 164, 1710 164, 1718 164, 1726 164, 1733 164, 1740 164, 1747 164, 1753 165, 1763 165, 1767 165, 1774 165, 1777 165, 1779 165, 1781 166, 1783 166, 1784 166, 1783 165, 1782 165, 1781 165, 1779 165, 1777 165\n",
              "</trace>\n",
              "<trace id=\"21\">\n",
              "1514 200, 1501 223, 1498 227, 1493 240, 1490 253, 1490 262, 1494 273, 1502 283, 1504 286, 1511 291, 1517 295, 1519 297, 1524 299, 1526 301, 1528 301, 1529 302, 1531 303, 1532 303, 1533 303, 1533 304, 1534 304, 1534 303, 1534 301, 1535 301, 1535 300, 1535 299, 1535 298\n",
              "</trace>\n",
              "<trace id=\"22\">\n",
              "1543 227, 1543 225, 1545 272, 1547 279, 1548 280, 1550 279, 1551 277, 1551 275, 1552 270\n",
              "</trace>\n",
              "<trace id=\"23\">\n",
              "1537 237, 1531 231, 1550 210, 1554 210, 1558 209, 1564 210, 1569 214, 1570 216, 1571 218, 1572 221, 1570 227, 1569 230, 1566 233, 1563 236, 1560 239, 1556 241, 1552 243, 1548 245, 1545 246, 1542 248, 1540 249, 1538 250, 1538 251, 1546 256, 1549 257, 1552 259, 1556 261, 1563 265, 1567 267, 1570 269, 1573 271, 1580 275, 1582 276, 1584 277, 1585 277, 1586 278, 1588 278, 1589 278, 1590 278, 1591 277, 1592 276, 1592 274\n",
              "</trace>\n",
              "<trace id=\"24\">\n",
              "1616 222, 1616 221, 1623 265, 1625 273, 1626 276, 1626 277, 1626 276, 1626 274, 1625 273, 1624 271\n",
              "</trace>\n",
              "<trace id=\"25\">\n",
              "1596 257, 1652 253, 1650 253\n",
              "</trace>\n",
              "<trace id=\"26\">\n",
              "1672 243, 1672 236, 1696 261, 1693 270, 1692 271, 1692 267, 1694 259, 1696 253, 1698 251, 1702 247, 1707 246, 1711 248, 1712 250, 1715 257, 1715 260, 1715 264, 1714 267, 1712 269, 1711 269, 1710 268, 1709 267, 1708 266, 1708 262, 1708 259, 1709 256, 1711 254, 1713 251, 1715 249, 1718 247, 1721 246, 1728 246, 1731 248, 1735 251, 1737 254, 1739 256, 1739 259, 1740 262, 1740 264, 1740 268, 1739 270, 1739 271, 1738 272, 1738 273, 1737 273, 1738 273, 1738 272, 1738 271\n",
              "</trace>\n",
              "<trace id=\"27\">\n",
              "1712 192, 1766 214, 1766 291, 1742 323, 1731 333, 1727 335, 1720 334, 1719 334, 1718 334\n",
              "</trace>\n",
              "<trace id=\"28\">\n",
              "1785 188, 1783 190, 1800 177, 1803 186, 1791 199, 1782 206, 1793 210, 1803 215, 1808 217, 1813 219, 1816 219, 1821 219, 1824 218, 1826 216\n",
              "</trace>\n",
              "<traceGroup xml:id=\"29\">\n",
              "<annotation type=\"truth\">From ITF</annotation>\n",
              "<traceGroup xml:id=\"30\">\n",
              "<annotation type=\"truth\">1</annotation>\n",
              "<traceView traceDataRef=\"0\"/>\n",
              "<annotationXML href=\"1_1\"/>\n",
              "</traceGroup>\n",
              "<traceGroup xml:id=\"31\">\n",
              "<annotation type=\"truth\">-</annotation>\n",
              "<traceView traceDataRef=\"1\"/>\n",
              "<annotationXML href=\"_1\"/>\n",
              "</traceGroup>\n",
              "<traceGroup xml:id=\"32\">\n",
              "<annotation type=\"truth\">r</annotation>\n",
              "<traceView traceDataRef=\"2\"/>\n",
              "<traceView traceDataRef=\"3\"/>\n",
              "<annotationXML href=\"r_1\"/>\n",
              "</traceGroup>\n",
              "<traceGroup xml:id=\"33\">\n",
              "<annotation type=\"truth\">2</annotation>\n",
              "<traceView traceDataRef=\"4\"/>\n",
              "<annotationXML href=\"2_1\"/>\n",
              "</traceGroup>\n",
              "<traceGroup xml:id=\"34\">\n",
              "<annotation type=\"truth\">=</annotation>\n",
              "<traceView traceDataRef=\"5\"/>\n",
              "<traceView traceDataRef=\"6\"/>\n",
              "<annotationXML href=\"=_1\"/>\n",
              "</traceGroup>\n",
              "<traceGroup xml:id=\"35\">\n",
              "<annotation type=\"truth\">1</annotation>\n",
              "<traceView traceDataRef=\"7\"/>\n",
              "<annotationXML href=\"1_2\"/>\n",
              "</traceGroup>\n",
              "<traceGroup xml:id=\"36\">\n",
              "<annotation type=\"truth\">-</annotation>\n",
              "<traceView traceDataRef=\"8\"/>\n",
              "<annotationXML href=\"_2\"/>\n",
              "</traceGroup>\n",
              "<traceGroup xml:id=\"37\">\n",
              "<annotation type=\"truth\">(</annotation>\n",
              "<traceView traceDataRef=\"9\"/>\n",
              "<annotationXML href=\"(_1\"/>\n",
              "</traceGroup>\n",
              "<traceGroup xml:id=\"38\">\n",
              "<annotation type=\"truth\">R</annotation>\n",
              "<traceView traceDataRef=\"10\"/>\n",
              "<traceView traceDataRef=\"11\"/>\n",
              "<annotationXML href=\"R_1\"/>\n",
              "</traceGroup>\n",
              "<traceGroup xml:id=\"39\">\n",
              "<annotation type=\"truth\">-</annotation>\n",
              "<traceView traceDataRef=\"12\"/>\n",
              "<annotationXML href=\"-_1\"/>\n",
              "</traceGroup>\n",
              "<traceGroup xml:id=\"40\">\n",
              "<annotation type=\"truth\">m</annotation>\n",
              "<traceView traceDataRef=\"13\"/>\n",
              "<annotationXML href=\"m_1\"/>\n",
              "</traceGroup>\n",
              "<traceGroup xml:id=\"41\">\n",
              "<annotation type=\"truth\">)</annotation>\n",
              "<traceView traceDataRef=\"14\"/>\n",
              "<annotationXML href=\")_1\"/>\n",
              "</traceGroup>\n",
              "<traceGroup xml:id=\"42\">\n",
              "<annotation type=\"truth\">2</annotation>\n",
              "<traceView traceDataRef=\"15\"/>\n",
              "<annotationXML href=\"2_2\"/>\n",
              "</traceGroup>\n",
              "<traceGroup xml:id=\"43\">\n",
              "<annotation type=\"truth\">+</annotation>\n",
              "<traceView traceDataRef=\"16\"/>\n",
              "<traceView traceDataRef=\"17\"/>\n",
              "<annotationXML href=\"+_1\"/>\n",
              "</traceGroup>\n",
              "<traceGroup xml:id=\"44\">\n",
              "<annotation type=\"truth\">1</annotation>\n",
              "<traceView traceDataRef=\"18\"/>\n",
              "<traceView traceDataRef=\"19\"/>\n",
              "<annotationXML href=\"1_3\"/>\n",
              "</traceGroup>\n",
              "<traceGroup xml:id=\"45\">\n",
              "<annotation type=\"truth\">-</annotation>\n",
              "<traceView traceDataRef=\"20\"/>\n",
              "<annotationXML href=\"_3\"/>\n",
              "</traceGroup>\n",
              "<traceGroup xml:id=\"46\">\n",
              "<annotation type=\"truth\">(</annotation>\n",
              "<traceView traceDataRef=\"21\"/>\n",
              "<annotationXML href=\"(_2\"/>\n",
              "</traceGroup>\n",
              "<traceGroup xml:id=\"47\">\n",
              "<annotation type=\"truth\">R</annotation>\n",
              "<traceView traceDataRef=\"22\"/>\n",
              "<traceView traceDataRef=\"23\"/>\n",
              "<annotationXML href=\"R_2\"/>\n",
              "</traceGroup>\n",
              "<traceGroup xml:id=\"48\">\n",
              "<annotation type=\"truth\">+</annotation>\n",
              "<traceView traceDataRef=\"24\"/>\n",
              "<traceView traceDataRef=\"25\"/>\n",
              "<annotationXML href=\"+_2\"/>\n",
              "</traceGroup>\n",
              "<traceGroup xml:id=\"49\">\n",
              "<annotation type=\"truth\">m</annotation>\n",
              "<traceView traceDataRef=\"26\"/>\n",
              "<annotationXML href=\"m_2\"/>\n",
              "</traceGroup>\n",
              "<traceGroup xml:id=\"50\">\n",
              "<annotation type=\"truth\">)</annotation>\n",
              "<traceView traceDataRef=\"27\"/>\n",
              "<annotationXML href=\")_2\"/>\n",
              "</traceGroup>\n",
              "<traceGroup xml:id=\"51\">\n",
              "<annotation type=\"truth\">2</annotation>\n",
              "<traceView traceDataRef=\"28\"/>\n",
              "<annotationXML href=\"2_3\"/>\n",
              "</traceGroup>\n",
              "</traceGroup>\n",
              "</ink>"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "getSoup(\"C:/Users/aiden/Downloads/ProjectData/LGINKML/INKMLs/2014train/80_jorge.inkml\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1_1\n",
            "['NTB']\n",
            "_1\n",
            "['BTD']\n",
            "r_1\n",
            "['Sup']\n",
            "2_1\n",
            "['DFS', 'UFD']\n",
            "=_1\n",
            "['UTF']\n",
            "1_2\n",
            "['NTB']\n",
            "_2\n",
            "['BTD']\n",
            "(_1\n",
            "['Right']\n",
            "R_1\n",
            "['Right']\n",
            "-_1\n",
            "['Right']\n",
            "m_1\n",
            "['Right']\n",
            ")_1\n",
            "['Sup']\n",
            "2_2\n",
            "['DFS', 'UFD']\n",
            "+_1\n",
            "['UTF']\n",
            "1_3\n",
            "['NTB']\n",
            "_3\n",
            "['BTD']\n",
            "(_2\n",
            "['Right']\n",
            "R_2\n",
            "['Right']\n",
            "+_2\n",
            "['Right']\n",
            "m_2\n",
            "['Right']\n",
            ")_2\n",
            "['Sup']\n",
            "2_3\n",
            "['DFS', 'UFD']\n",
            "['1', 'NTB', '-', 'BTD', 'r', 'Sup', '2', 'DFS-UFD', '=', 'UTF', '1', 'NTB', '-', 'BTD', '(', 'Right', 'R', 'Right', '-', 'Right', 'm', 'Right', ')', 'Sup', '2', 'DFS-UFD', '+', 'UTF', '1', 'NTB', '-', 'BTD', '(', 'Right', 'R', 'Right', '+', 'Right', 'm', 'Right', ')', 'Sup', '2', 'DFS-UFD']\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[30,\n",
              " 5,\n",
              " 26,\n",
              " 6,\n",
              " 115,\n",
              " 2,\n",
              " 31,\n",
              " 15,\n",
              " 40,\n",
              " 4,\n",
              " 30,\n",
              " 5,\n",
              " 26,\n",
              " 6,\n",
              " 23,\n",
              " 0,\n",
              " 55,\n",
              " 0,\n",
              " 26,\n",
              " 0,\n",
              " 110,\n",
              " 0,\n",
              " 24,\n",
              " 2,\n",
              " 31,\n",
              " 15,\n",
              " 25,\n",
              " 4,\n",
              " 30,\n",
              " 5,\n",
              " 26,\n",
              " 6,\n",
              " 23,\n",
              " 0,\n",
              " 55,\n",
              " 0,\n",
              " 25,\n",
              " 0,\n",
              " 110,\n",
              " 0,\n",
              " 24,\n",
              " 2,\n",
              " 31,\n",
              " 15]"
            ]
          },
          "execution_count": 37,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "convert_relations(\"C:/Users/aiden/Downloads/ProjectData/LGINKML/LGs/2014train/80_jorge.lg\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "defaultdict(<function __main__.<lambda>()>,\n",
              "            {'Right-Right': 119,\n",
              "             'UFD-OFI': 3,\n",
              "             'Inside-Inside': 8,\n",
              "             'OFI-OFI': 5,\n",
              "             'UFS-DFS': 4,\n",
              "             'Sup-Sup': 10,\n",
              "             'UFD-UTF': 10,\n",
              "             'UFD-DFS-UFD': 8,\n",
              "             'UFS-UFS': 5,\n",
              "             'Sub-Sub': 2,\n",
              "             'UFS-OFI': 1,\n",
              "             'UTF-UTF': 4,\n",
              "             'BTD-BTD': 4,\n",
              "             'DFS-UFD-OFI-UFD': 1,\n",
              "             'UFD-DFS-NTB': 2,\n",
              "             'UFD-UFD': 6,\n",
              "             'UFS-UFD-OFI': 1,\n",
              "             'UFS-OFI-NTB': 1,\n",
              "             'UFD-NTB': 2,\n",
              "             'DFS-DFS-DFS-DFS-DFS': 1,\n",
              "             'UFS-UTF': 1,\n",
              "             'OFI-UFD-OFI': 2,\n",
              "             'UFS-DFS-NTB': 17,\n",
              "             'UFS-DFS-UFD': 17})"
            ]
          },
          "execution_count": 183,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "missing_relations_freq"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "with open(\"C:/Users/aiden/Downloads/ProjectData/Vocab.pkl\", \"rb\") as f:\n",
        "    vocab=pkl.load(f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "datapath=\"C:/Users/aiden/Downloads/ProjectData/FeatureData/\"\n",
        "with open(datapath+\"X_Y_Vocab\", \"rb\") as f:\n",
        "    X, Y, vocab = pkl.load(f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "length = len(X)\n",
        "vocab_size = len(vocab)\n",
        "X_train = []\n",
        "Y_train = []\n",
        "X_test = []\n",
        "Y_test = []\n",
        "for i in range(length):\n",
        "    if (i%10):\n",
        "        X_train.append(X[i])\n",
        "        Y_train.append(Y[i])\n",
        "    else:\n",
        "        X_test.append(X[i])\n",
        "        Y_test.append(Y[i])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "datapath=\"C:/Users/aiden/Downloads/ProjectData/FeatureData/\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "with open(datapath+\"Train\", \"wb\") as f:\n",
        "    pkl.dump((X_train, Y_train, vocab), f)\n",
        "with open(datapath+\"Test\", \"wb\") as f:\n",
        "    pkl.dump((X_test, Y_test, vocab), f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "X_train=[]\n",
        "Y_train=[]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "with open(datapath+\"Train\", \"rb\") as f:\n",
        "    X_train, Y_train, _ = pkl.load(f)\n",
        "#with open(datapath+\"Test\", \"wb\") as f:\n",
        "#    pkl.load((X_test, Y_test, vocab), f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "25\n"
          ]
        }
      ],
      "source": [
        "print(len(X_train[5]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'X_test' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[149], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m len_X_train\u001b[39m=\u001b[39m\u001b[39mlen\u001b[39m(X_train)\n\u001b[0;32m      3\u001b[0m len_Y_train\u001b[39m=\u001b[39m\u001b[39mlen\u001b[39m(Y_train)\n\u001b[1;32m----> 4\u001b[0m len_X_test\u001b[39m=\u001b[39m\u001b[39mlen\u001b[39m(X_test)\n\u001b[0;32m      5\u001b[0m len_Y_test\u001b[39m=\u001b[39m\u001b[39mlen\u001b[39m(Y_test)\n\u001b[0;32m      6\u001b[0m max_X_train_len \u001b[39m=\u001b[39m \u001b[39mmax\u001b[39m([\u001b[39mlen\u001b[39m(sample) \u001b[39mfor\u001b[39;00m sample \u001b[39min\u001b[39;00m X_train])\n",
            "\u001b[1;31mNameError\u001b[0m: name 'X_test' is not defined"
          ]
        }
      ],
      "source": [
        "num_of_features=7\n",
        "len_train=len(X_train)\n",
        "len_test=len(X_test)\n",
        "max_X_train_len = max([len(sample) for sample in X_train])\n",
        "max_Y_train_len = max([len(sample) for sample in Y_train])\n",
        "max_X_test_len = max([len(sample) for sample in X_test])\n",
        "max_Y_test_len = max([len(sample) for sample in Y_test])\n",
        "padding_vector=np.ones(7)\n",
        "eos_index=0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "639\n",
            "87\n",
            "1333\n"
          ]
        }
      ],
      "source": [
        "print(max_X_len)\n",
        "print(max_Y_len)\n",
        "print(len_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "X_train_data_len=[len(data) for data in X_train]\n",
        "Y_train_data_len=[len(data) for data in Y_train]\n",
        "X_test_data_len=[len(data) for data in X_test]\n",
        "Y_test_data_len=[len(data) for data in Y_test]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "padded_X_train=np.zeros((len_train, max_X_train_len, num_of_features))+padding_vector\n",
        "padded_Y_train=np.zeros((len_train, max_Y_train_len))+eos_index\n",
        "padded_X_test=np.zeros((len_test, max_X_test_len, num_of_features))+padding_vector\n",
        "padded_Y_test=np.zeros((len_test, max_Y_test_len))+eos_index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for i in range(len_train):\n",
        "    sample_X = X_train[i]\n",
        "    padded_X_train[i,:len(sample_X)]=sample_X\n",
        "    sample_Y = Y_train[i]\n",
        "    padded_Y_train[i,:len(sample_Y)]=sample_Y\n",
        "for i in range(len_test):\n",
        "    sample_X = X_test[i]\n",
        "    padded_X_test[i,:len(sample_X)]=sample_X\n",
        "    sample_Y = Y_test[i]\n",
        "    padded_Y_test[i,:len(sample_Y)]=sample_Y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "11988\n",
            "1333\n"
          ]
        }
      ],
      "source": [
        "print(len(X_train))\n",
        "print(len(X_test))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "tf",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.16"
    },
    "vscode": {
      "interpreter": {
        "hash": "6737d4ed9008f34a36365f9afa168c058c7bcfc27ae9ebfad5913b219a0345d6"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
